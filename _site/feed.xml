<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-01-24T22:57:53+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Woongjoon_AI</title><subtitle>AMazing developer</subtitle><author><name>Choi Woongjoon</name></author><entry><title type="html">Pytorch data api : worker, pinned memory, prefetch, non-blocking?? 이 것들이 다 설정되면 어떻게 작동할까요?</title><link href="http://localhost:4000/pytorch/Data-loading/" rel="alternate" type="text/html" title="Pytorch data api : worker, pinned memory, prefetch, non-blocking?? 이 것들이 다 설정되면 어떻게 작동할까요?" /><published>2024-01-24T00:00:00+09:00</published><updated>2024-01-24T00:00:00+09:00</updated><id>http://localhost:4000/pytorch/Data-loading</id><content type="html" xml:base="http://localhost:4000/pytorch/Data-loading/"># Pin-memory,worker,pre-fetch,gpu non-blocking을 다 합쳐서 생각해보자. 
pytorch의 docs를 보면서 worker라는 configuration을 지정해 주면 단순히 worker라는 게 생겨서 data를 loading 해준다고만만 알고 있었습니다. 이를, pin-memory,pre-fetch , GPU non-blocking과 결합을 하는 순간 어떻게 동작하는 것인지 전혀 이해를 못 하는 저 자신을 보게 되었습니다. Pytorch자체는 high-level API를 제공하는 framework이지만, 이 configuration은 deep learning model의 훈련을 low-level에서 설정해서 진행하도록 해주는 것임을 알게 되었습니다. low-level에서 훈련 configuration을 조정하는 것은 딥러닝 엔지니어로서 만이  아니라 소프트웨어 엔지니어로써의 역량향상에 도움이 될 것이라 여겨집니다.  

!! Asynchronous ,Sychronous가 무엇인자 모른다면 이 [post]()를 보시고 오기를 권장합니다. 
## worker
Pytorch의 DataLoader class를 보면 num_worker라는 configuration이 있습니다.num_worker에 대한 설명은 다음과 같습니다.
```
num_workers (int, optional) how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)
```

subprocess가 fork()로 생성되어(unix의 경우), batch_size * num_worker만큼의 data를 로딩하게 됩니다. 여기서, 주목해야 할 점은 호출하는 main process는 worker에 대해 asynchronous 하다는 점입니다. 즉, main process가 data를 GPU로 로딩하고 훈련하게 되면, num worker는 parallel 하게 data를 fetching 하게 됩니다.worker는 data를 read하는 I/O operation이기에 worker는 main process를 non-blocking 한다고 할 수 있습니다.

num_worker configuration을 사용할 때 주의점은 CPU의 메모리를 얼마나 잡아먹는지를 고려하면서 사용해야 한다는 점입니다. parent process와 똑같은 양의 CPU 메모리를 worker process가 차지하게 되는데, 만약에 Datset Class가 매우 큰 List를 포함하고 있다면 `worker * parent process size`만큼의 메모리를 차지하게 될 것입니다. 

## Pin memory

Pin Memory에 대한 pytorch의 설명은 다음과 같습니다.
&gt;pin_memory (bool, optional) If True, the data loader will copy Tensors into device/CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below.

Tensor를 pinned memory에 복사한다는 것이 무슨 의미인지 알아보도록 하겠습니다. 

### nvidia

![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217834&amp;authkey=%21ALlP7XyB6BzlyAo&amp;width=717&amp;height=379)

Cuda 에서 host에서 device(GPU)로 data를 전송하기 위해서는 임시로 lock 된 page, pinned memory에 data를 전송해야만 합니다. 그다음에, device로 data를 전송하게 됩니다. git의 staging area와 비슷한 개념이라 볼 수 있습니다. git에서 commit 객체로 변경 사항을 이동시키기 위해서는 staging area를 거치는 것과 유사한 개념입니다.
Pinned memory를 고정해 놓음으로써 host의 pageable memory와 pinned memory 사이의 전송 cost를 없앨 수 있습니다.  

## prefetch
prefetch의 pytorch docs의 정의는 다음과 같습니다.  

&gt;prefetch_factor (int, optional, keyword-only arg) Number of batches loaded in advance by each worker. 2 means there will be a total of 2 * num_workers batches prefetched across all workers. (default value depends on the set value for num_workers. If value of num_workers=0 default is None. Otherwise, if value of num_workers &gt; 0 default is 2).  

모든 worker가 prefetch * batch_size만큼의 data를 미리 loading 하게 됩니다. 따라서, Disk와 host 간의 통신이 줄어들게 되어 overhead를 많이 줄일 수 있게 됩니다. 하지만, 이 역시 CPU의 spec을 고려해서 잘 설정해야 합니다.  
### In My opinion
제 생각에는 실제로 써먹기 힘든 옵션이라 생각합니다.gpu가 data를 기다리는 상황이 얼마나 발생할지에 따라 달라질 수 있습니다. 하지만 ,  하드웨어 리소스가 이 정도로 충분하다면 , 애초에 하드웨어의 스펙을 최적화해서 단가를 낮추는 게 더 경제적이라고 생각합니다. 

## non_blocking
non block의 pytorch docs의 정의는 다음과 같습니다. 

&gt; Returns a Tensor with the specified device and (optional) dtype. If dtype is None it is inferred to be self.dtype. When non_blocking, tries to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor. When copy is set, a new Tensor is created even when the Tensor already matches the desired conversion.

이 option은 pinned_memory 가 true 설정되어 있다면, 즉 pinned memory가 고정되어 있을 때 사용할 수 있는 옵션입니다. host는 tensor의 GPU로의 전송에 대해 asynchronous 하게 됩니다. 즉, tensor를 GPU로 전송하는 함수를 host는 신경 쓰지 않고 다음 동작을 수행하게 됩니다. 이에 대해, 내부적으로 어떻게 작동하는지 NVIDIA의 docs를 통해 알아보도록 하겠습니다.


### nvidia
![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217835&amp;authkey=%21AK_rXcRO4cr-r1s&amp;width=1139&amp;height=727)  

이 그림에서 h2d는 device에서 host로의 data 전송, kernel은 병렬 computation,d2h는 device에서의 hardware로의 data 전송을 의미합니다.
NVIDIA의 Cuda 에서는 data를 작은 chunk들로 쪼갠 다음에, data transfer와 computation을 scheduling 하여 bottleneck을 줄인다고 합니다 .
여기서, sequential 버전의 경우 ,h2d 와 관련된 stream(함수)은 host에 non-block이면서, host는 h2d stream에 대하여 asynchronous 합니다. 제어권이 다시 host에 돌아오기 때문에, computation을 병렬적으로 진행되게 됩니다.

### 주의점

 염두에 둬야 할 것이 있습니다. non-blocking configuration을 설정하는 것 자체는 program에 나쁜 점은 없습니다. 하지만, 실제로 non-blocking을 사용하는 것과 사용하지 않은 것의 차이가 없을 수 있습니다. 병렬적으로 computation을 하지 못하고 모든 small chunk data를 기다려야 하는 지점, 즉 sync point 때문입니다. 예를 들어, tensor를 transformation 하는 것은 small chunk에 대해 각각 적용되어도 최종 결과에는 차이가 없습니다. 하지만, 특정 dimension에 대해 normalize를 하는 경우, 예를 들어 batch normalization, batch 전체에 대한 statistic을 계산해야 하기에 hots 는 batch norm 함수에 대해 synchronous여야 합니다.

 즉, model의 computation에 대한 수학적인 이해가 바탕이 되지 않는다면 성능에 대한 profiling을 할 수 없을 것입니다. 

## All together
worker, pinned memory, prefetch, non blocking을 전부 합쳐서 data fetching 과정을 설명해보도록 하겠습니다.  
![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217836&amp;authkey=%21AO0XjU31chGSrI8&amp;width=730&amp;height=414)  
pin memory configuration이 설정되어있고 num_worker는 2 로 설정되었습니다. 따라서, main process(host)는 batch * 2 만큼의 data를 pinned memory에 loading 하게 됩니다.  
![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217837&amp;authkey=%21AKiwiniQwNuDN2o&amp;width=696&amp;height=463)  
data가 device(gpu)로 전송이 되면 , host는 data 전송에 대해 asynchronous 하기 때문에 dataloader는 다음 batch data를 pinned memory에 로딩하게 됩니다.  
![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217838&amp;authkey=%21AE0hAnAwRJMia-4&amp;width=750&amp;height=451)  
prefetch factor가 설정된다면,  prefetch factor*worker*batch만큼의 data를 loading하게 됩니다. 나머지 과정은 위와 동일하게 진행이 될 것입니다.  

![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217839&amp;authkey=%21AJHSTuTRWcQ3g2s&amp;width=1091&amp;height=622)  
non-blocking이 설정이 된다면, 내부적으로 async version 2와 같이 data transfer와 computation이 overlap 될 것입니다. d2h transfer가 일어나는 때는 ,output을 cpu로 다시 전송하거나 model의 parameter를 update하면서 checkpoint를 host에 연결된 디스크에 저장하거나 같은 상황입니다.   

## Conclusion 

Data transfer를 computation과 overlap 하는 것을 추상화된 high-level API 관점에서만 사용할 수도 있습니다. 하지만, 저는 이를 좀 더 low-level에서 보았고, overlap이나 optimize가 어떻게 일어나는지 알게 되었습니다. high-level API에만 의존하고 내부 동작을 모르게 되면, 특정 librarary에 종속되어 customize나 debugging이 어려워집니다. low-level에서 어떻게 작동하는지를 고민하게 되면, customize와 debugging이 용이하게 되고, 동작에 대한 이해도가 더 깊어집니다. 또한, Computer Science에 대한 이해도가 깊어지고, 문제해결 능력이 향상되고, 뿐만 아니라 새로운 기술을 더 쉽게 배우는 데 도움이 됩니다. 아직 Junior의 입장이고, 정년은 더욱더 늘어나는 시대이기에 low-level로 생각하는 연습을 계속할 것입니다.

## References

https://d2.naver.com/helloworld/3773258


https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/

https://discuss.pytorch.org/t/when-does-a-pytorch-dataset-worker-pull-new-data/153286


https://discuss.pytorch.org/t/how-to-maximize-cpu-gpu-memory-transfer-speeds/173855/4


https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async


https://discuss.pytorch.org/t/non-blocking-memory-transfer-to-gpu/188941


https://discuss.pytorch.org/t/should-we-set-non-blocking-to-true/38234/24


https://discuss.pytorch.org/t/doing-data-augmnetation-in-parallel/90685/2


https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html</content><author><name>Choi Woongjoon</name></author><category term="Pytorch" /><category term="Machine Learning" /><category term="Pytorch" /><category term="deep learning" /><category term="DeepLearning General Method" /><summary type="html">Data Transfer optimization and overlap</summary></entry><entry><title type="html">Syncrhonize,Asyncrhonize vs Non-blocking,Blocking : Synchronize와 Blocking은 같은거 아닌가?</title><link href="http://localhost:4000/development/Sync-vs-Async-Block-vs-Nonblock/" rel="alternate" type="text/html" title="Syncrhonize,Asyncrhonize vs Non-blocking,Blocking : Synchronize와 Blocking은 같은거 아닌가?" /><published>2024-01-23T00:00:00+09:00</published><updated>2024-01-23T00:00:00+09:00</updated><id>http://localhost:4000/development/Sync-vs-Async-Block-vs-Nonblock</id><content type="html" xml:base="http://localhost:4000/development/Sync-vs-Async-Block-vs-Nonblock/">&lt;h1 id=&quot;syncrhonizeasyncrhonizenon-blockingblocking&quot;&gt;Syncrhonize,Asyncrhonize,Non-blocking,Blocking??&lt;/h1&gt;
&lt;p&gt;요새 딥러닝 프레임워크인 pytorch docs를 읽다가 blocking이라는 단어를 보게 되었습니다. blocking이라는 단어가 별 뜻이 없는 줄 알았는데, 관련 내용을 forum에서 찾아보다가 NVIDIA의 패트릭 형님이 깊은 이해를 위한 링크를 달아주신 걸 보았습니다. NVIDIA의 post였는데 blocking, non-blocking, synchronize,asynchronize가 수십번은 반복되는데, 내용이 전혀 이해되지 않았습니다. blocking, non-blocking을 검색하면서 이 개념은 프로세스의 동작 제어와 관련한한 내용임을 알았습니다. synchronize, asyncrhonize와 blocking, non-blocking은 다른 개념이라는 사실을 처음 알게 되었습니다. 관련 포스트를 보면서, synchronize, asyncrhonize를 세부적으로 이해하지 못하고 있음을 알았습니다. 엔지니어로서 동작 제어권은 프로세스를 설계하는 데 중요하므로 꼭 알아야 한다는 생각이 듭니다.&lt;/p&gt;
&lt;h2 id=&quot;sync-vs-async&quot;&gt;Sync vs Async&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://onedrive.live.com/embed?resid=7E81BBCD99889380%217840&amp;amp;authkey=%21APnBHuRo6P7JPu0&amp;amp;width=435&amp;amp;height=250&quot; alt=&quot;image&quot; /&gt;&lt;br /&gt;
위 그림은 Synchronous, Asynchronous 를 나타내는 그림입니다. 그림을 보면 프로세스 A가 프로세스 B의 동작을 기다리는지가 차이점입니다. 이를 일반적으로 정의해보겠습니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;synchronization is the task of coordinating multiple of processes to join up or handshake at a certain point, in order to reach an agreement or commit to a certain sequence of action.&lt;/li&gt;
  &lt;li&gt;Asynchrony, in computer programming, refers to the occurrence of events independent of the main program flow and ways to deal with such events.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sync ,Async 는 앞에 철자 a가 붙어있기 때문에 반대되는 개념이라고 예측이됩니다. 하지만, 설명이 반대되는 내용이 아닌거 같습니다. 아래의 reference에서 본 설명이 이해가 잘 되었기에 그대로 적어보도록 하겠습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;synchronization은 B process를 호출한 process A가 B process의 처리결과를 신경써서 기다리는 것이다.&lt;/li&gt;
  &lt;li&gt;asynchronization은 B process를 호출한 process A 가 B process의 처리결과를 신경쓰지 않고 기다리지 않고 자신의 동작을 수행한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;호출한 process A가 특정 부분에서 다른 process를 호출하고 동작의 순서가 특정한 순서가 되도록 하는 것은 process A가 나머지 process들의 처리결과를 신경쓴다고 볼 수 있습니다.&lt;br /&gt;
main program ,즉 process A와 특정 이벤트를 처리하는 방법, 즉 process B과 서로 신경쓰지 않고  process B가 발생합니다. process A가 process B의 처리결과를 신경쓰지 않고 자신의 동작을 수행함과 같은 의미입니다.&lt;/p&gt;
&lt;h2 id=&quot;block-vs-nonblock&quot;&gt;Block vs Nonblock&lt;/h2&gt;
&lt;p&gt;blocking,non blocking은 I/O api에서 사용되는 개념입니다. data를 read하거나 write하는 등의 작업이 I/O 작업입니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Blocking : approach to I/O would be to start the access and then wait for it to complete.&lt;/li&gt;
  &lt;li&gt;Non-locking : a form of input/output processing that permits other processing to continue before the I/O operation has finished.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;앞의 sync,async에 비해 설명이 명시적으로 반대의 성질을 갖고 있습니다. blocking은 호출되면 제어권을 호출한 process에게 넘겨주지 않고 , non-blocking은 호출한 process에게 제어권을 넘겨줍니다. 이를 간단하게 정의하면 다음과 같습니다. 이번에도, reference의 블로그의 설명을 그대로 차용했습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;blocking : 호출된 함수가 호출한 함수에게 자신의 동작이 끝날때 까지 제어권을 넘겨주지 않는다.&lt;/li&gt;
  &lt;li&gt;non-blocking : 호출된 함수가 자신의 동작이 끝나지 않았음에도 호출한 함수에게 바로 제어권을 넘겨줍니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;four-patterns&quot;&gt;Four patterns&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://onedrive.live.com/embed?resid=7E81BBCD99889380%217846&amp;amp;authkey=%21AIFoSWztVEf8__U&amp;amp;width=280&amp;amp;height=230&quot; alt=&quot;image&quot; /&gt;&lt;br /&gt;
이번에는 sync,async 그리고 blocking,non blocking을 결합한 모든 경우 4가지를 살펴보도록 하겠습니다. 아래의 예시들은 IBM의 블로그에서 가져왔습니다.&lt;/p&gt;
&lt;h3 id=&quot;synchronous-blocking-io&quot;&gt;Synchronous blocking I/O&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://onedrive.live.com/embed?resid=7E81BBCD99889380%217845&amp;amp;authkey=%21ACDJFjlBed31WXw&amp;amp;width=768&amp;amp;height=493&quot; alt=&quot;image&quot; /&gt;&lt;br /&gt;
user application이 system call을하고 system call이 완료될 때 까지 system call이 application을 block합니다. 
여기서 cpu를 차지하지 않고 system call의 response를 기다리고 있기에 효율적이라 볼 수 있다고 합니다.&lt;br /&gt;
read system call이 호출되면 , system call이 application을 block하고 context는 kernel 전환되어집니다.&lt;/p&gt;

&lt;h3 id=&quot;synchronous-non-blocking-io&quot;&gt;Synchronous non-blocking I/O&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://onedrive.live.com/embed?resid=7E81BBCD99889380%217849&amp;amp;authkey=%21APD7PUTY2InbhPo&amp;amp;width=546&amp;amp;height=392&quot; alt=&quot;image&quot; /&gt;&lt;br /&gt;
이 case에서는 user application이 system call을 요청하는데 , read는 error를 return하고 call이 수행되지 않습니다. 대부분의 case에서 user application은 data를 읽어야 다음 작업을 수행할 수 있기에 무수히 많은 system call을 read가 수행될 떄 까지 하게 됩니다.&lt;br /&gt;
data가 kerenl에서 접근이 가능해지고 , user 가 호출한 read가 다시 return 되기 까지의 시간이 길어지기에  , IO에서 latency가 증가되고, 따라서 전체적인 처리량이 감소하게 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;asynchronous-blocking-io&quot;&gt;Asynchronous blocking I/O&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://onedrive.live.com/embed?resid=7E81BBCD99889380%217849&amp;amp;authkey=%21APD7PUTY2InbhPo&amp;amp;width=546&amp;amp;height=392&quot; alt=&quot;image&quot; /&gt;&lt;br /&gt;
이 case에서는 user application이 select라는 system call을 요청하는 case입니다. select는 file descriptor가 쓰기 가능한지, 읽기 가능한지 에 대한 것을 알려줍니다. 하나의 file descriptor만이 아니라 1024 이하의 file descriptor에 대해 알려주게 됩니다. 여기서, user application은 다음 작업을 하러 가도 됩니다. 즉, asynchronous합니다. 하지만,select가 user application을 blocking 하기에 기다리게 됩니다.&lt;br /&gt;
이 select는 비효율적이기에 고성능 I/O에서 사용되는 것은 권장되지 않는다고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;asynchronous-non-blocking-io-aio&quot;&gt;Asynchronous non-blocking I/O (AIO)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://onedrive.live.com/embed?resid=7E81BBCD99889380%217848&amp;amp;authkey=%21AKSg7EXa9R4YtLk&amp;amp;width=559&amp;amp;height=388&quot; alt=&quot;image&quot; /&gt;&lt;br /&gt;
asynchronous non-blocking I/O 모델은 호출한 process와 I/O의 작업을 overlap하여 실행하게 됩니다. user application이 aio_read라는 system call을 하게되면 read가 성공했다고 즉시 return을 받게됩니다. user application은 다른 process를 수행하면서, 동시에 background에서는 I/O가 read를 수행하고 있습니다.  read의 response가 user application에 도착하면 , signal이나 callback이 발생하여 data가 kernel에서 user application으로 전송되게 됩니다. 
여러 I/O 요청에 대해 단일 프로세스에서의 계산과 I/O처리를 겹치는 것은 프로세스의 처리속도와 I/O의 처리속도의 차이를 최대한 활용합니다. 하나 이상의 느린 I/O요청이 처리되는 동안 CPU는 프로세스의 다른 작업을 처리할 수 있고, I/O가 처리가 되면 CPU는 이에 대해 동작을 수행하고 동시에 새로운 I/O요청이 수행됩니다.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Program을 코드로 작성할 때 원하는 동작을 하는지에 대해만 관심이 있었을 뿐 , device가 computer의 resource를 얼마나 효율적으로 활용하는지에 대해서는 크게 신경을 안쓰고 있었다는 것을 깨달았습니다. Operating System수업을 학부시절에 들었지만, 이를 실제로 제 Program에 어떻게 접목시킬지는 크게 고민을 안해봤습니다.지금부터라도 , Operating System에서 배웠던 지식들을 어떻게 제 Program에 접목시킬지를 고민해보고 추가적으로 Operating System을 더 깊이있게 공부해야 함을 깨달았습니다.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;https://musma.github.io/2019/04/17/blocking-and-synchronous.html&lt;/p&gt;

&lt;p&gt;https://developer.ibm.com/articles/l-async/&lt;/p&gt;

&lt;p&gt;https://en.wikipedia.org/wiki/Asynchronous_I/O&lt;/p&gt;

&lt;p&gt;https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)&lt;/p&gt;

&lt;p&gt;https://en.wikipedia.org/wiki/Synchronization_(computer_science)&lt;/p&gt;</content><author><name>Choi Woongjoon</name></author><category term="Development" /><category term="SoftwareEngineering" /><category term="Resource Management" /><summary type="html">I/O , CPu overlaping</summary></entry><entry><title type="html">Integer Internal Implementation after 3.12</title><link href="http://localhost:4000/python/Integer-internal/" rel="alternate" type="text/html" title="Integer Internal Implementation after 3.12" /><published>2024-01-21T00:00:00+09:00</published><updated>2024-01-21T00:00:00+09:00</updated><id>http://localhost:4000/python/Integer-internal</id><content type="html" xml:base="http://localhost:4000/python/Integer-internal/"># Integer Internal after Python 3.12

파이썬을 사용하면서 정수와 같은 numeric object를 사용하게 된다. 정수를 사용하다 보면, arbitary precision을 지원한다는 사실이 놀랍지만, 그냥 받아들이면서 했다. 이에 대해 신경쓰지 않아도 추상화가 잘 되어있기에 , 괜찮을 수 있다. 하지만, 좀 더 좋은 엔지니어가 되기 위해서는 high-level이아닌 low-level에서 어떻게 작동하는지 볼줄 알아야 한다고 생각한다. high-level로 추상화된 동작을 분해하는 것은 문제를 분해하는 것과 같은 이치기에 문제해결능력에 도움이 될 것이라 생각한다. 또한, low-level에 구현을 이해하면 다른 영역에서도 이 idea를 적용할 가능성이 높을 것이다. 

## Internal Representation
### Definition
```c
#define PyObject_HEAD                   PyObject ob_base;

typedef uint32_t digit;

typedef struct _PyLongValue {
    uintptr_t lv_tag; /* Number of digits, sign and flags */
    digit ob_digit[1];
} _PyLongValue;

struct _longobject {
    PyObject_HEAD
    _PyLongValue long_value;
};
```

파이썬의 int class는 _longobject라는 struct를 이용해서 구현됩니다. PyObject_HEAD는 PyObject의 초기 세그먼트를 정의한다는 의미입니다. PyObject는 모든 파이썬 Object의 기본타입입니다. 이 PyObject는 Compiler의 Parser Tree의 계층화 개념을 사용한 거 같습니다. Compiler의 PaserTree에서는 토큰을 계층화해서 최상위토큰에서 하위토큰으로 program을 구조화합니다. PyObject는 최상위토큰으로 보입니다. PyObject_HEAD는 객체의 참조 타입, 크기 등의 정보를 담고 있습니다. PyObject_HEAD는 파이선 C API에서 객체를 생성하거나 조작할 때 필요한 매크로입니다. 매크로란 특정한 입력 시퀸스(문자열)가 어떤 시퀸스로 매핑이 되는지에 대한 규칙이나 패턴입니다. 여기서는 #define이 매크로입니다.

lv_tag는 몇 자릿수인지 , 부호는 어떻게 되는지, 기타 연산에 필요한 flag 등을 저장합니다.
ob_digit은 32bit int에 대한 배열, 즉 포인터입니다. 하지만, 여기서 ob_digit가 크기가 1인 배열이라는 것을 확인할 수 있습니다. ob_digit은 값이 저장되는 배열인데, 크기가 1이라 지정되면 그 이상의 크기를 할당할 때, Segmentation Fault 오류를 발생시킵니다. 하지만, 파이썬은 arbitary precision을 지원하는 것으로 알려져 있습니다.
이는 c struct의 flexible array member를 사용한 것입니다. flexible array member는 struct 의 마지막 멤버에 가변길이의 배열을 설정할 수 있게 하는 개념입니다.  
```c
result = PyObject_Malloc(offsetof(PyLongObject, long_value.ob_digit) +
                             ndigits*sizeof(digit));
```
실제로 할당시에 ,필요한 digit만큼의 메모리를 할당해주어 arbiratry precision을 지원할 수 있게 됩니다. 
### ob_digit

이제는 ob_digit에 대해 알아보겠습니다. ob_digit에는 digit type의 값이 저장됩니다. digit은 uint32_t를 확장한 macro입니다. 앞으로, digit을 32bit integer라 여기고 digit이라는 용어만을 사용하겠습니다.

ob_digit은 정숫값을 나타내며, 배열의 각 원소는 자릿수입니다 .  0부터 1의 자릿수로 취급하며 index가 올라갈 때마다 자릿수가 올라가게 됩니다. 만약에, 정수를 10진법으로 표현하게 되면 상당히 많은 자릿수가 필요하게 됩니다. 32bit 크기의 data를 저장할 수 있도록 정의되었는데, 10까지의 숫자만을 저장하게 되면, 저장공간의 낭비가 됩니다. 따라서, Python은 10진법이 아닌 $$2^{30}$$ 진법, 즉 base가 $$2^{30}$$ 인 수 체계를 활용하게 됩니다. $$2^{30}$$ 인 이유는 overflow 및 underflow를 방지하기 위한 base의 최대치가 $$2^{30}$$이기 때문입니다. 

### 3.12 이전과 차이점
Integer의 internal을 다룬 모든 post는 아래와 같은 struct를 기준으로 설명을 합니다.  
```c
struct _longobject {
    PyObject_VAR_HEAD
    digit ob_digit[1];
};

typedef struct {
    PyObject ob_base;
    Py_ssize_t ob_size; /* Number of items in variable part */
} PyVarObject;
```
제가 위에서 설명한 struct와 정의가 다름을 알 수 있습니다.  이에 대해 열심히 찾아보다가 cpython의 issue에서 이에 대한 내용을 발견하였습니다. 

```
I think in the What's New in 3.12 we should at least mention the change in the struct (calling out that using ob_size and ob_digits is no longer supported) and the new unstable public APIs (and what they're for).

```
https://github.com/python/cpython/issues/101291#issuecomment-1646132302  

이는 gvanrossum, 파이썬 창시자의 comment입니다. 더 이상 ob_size가 사용되지 않고 lv_tag라는 새로운 representation으로 대체 되었다는 얘기입니다. 사실상, 이전과 기능의 차이는 나지 않기에 만약에 cpython의 source code를 살펴본다면 , 기억만 해두면 좋을거 같습니다.  

## Add
```c
/* Add the absolute values of two integers. */

static PyLongObject *
x_add(PyLongObject *a, PyLongObject *b)
{
    Py_ssize_t size_a = _PyLong_DigitCount(a), size_b = _PyLong_DigitCount(b);
    PyLongObject *z;
    Py_ssize_t i;
    digit carry = 0;

    /* Ensure a is the larger of the two: */
    if (size_a &lt; size_b) {
        { PyLongObject *temp = a; a = b; b = temp; }
        { Py_ssize_t size_temp = size_a;
            size_a = size_b;
            size_b = size_temp; }
    }
    z = _PyLong_New(size_a+1);
    if (z == NULL)
        return NULL;
    for (i = 0; i &lt; size_b; ++i) {
        carry += a-&gt;long_value.ob_digit[i] + b-&gt;long_value.ob_digit[i];
        z-&gt;long_value.ob_digit[i] = carry &amp; PyLong_MASK;
        carry &gt;&gt;= PyLong_SHIFT;
    }
    for (; i &lt; size_a; ++i) {
        carry += a-&gt;long_value.ob_digit[i];
        z-&gt;long_value.ob_digit[i] = carry &amp; PyLong_MASK;
        carry &gt;&gt;= PyLong_SHIFT;
    }
    z-&gt;long_value.ob_digit[i] = carry;
    return long_normalize(z);
}

```

Python 임의의 자릿수 정수 a, b의 덧셈 구현입니다. a, b라는 두 정수를 parameter로 받는데, a의 자릿수가 항상 b보다 크게끔 설정을 해줍니다.
그리고, a보다 자릿수가 하나 더 많은 수 z를 생성해 줍니다.
1의 자릿수부터 더해 나가기 시작하는데 carry와 PyLong_MASK라는 것의 and 연산 결과를 1의 자릿수에 할당해 줍니다.
PyLong_MASK는 bit 30개가 1로 masking 되어 있는 정수입니다. 001111…. 111과 같이 32bit가 구성되어 있습니다. 파이썬의 integer는 base가 $$2^{30}$$ 인 수이기 때문에, 30개의 bit의 값만을 z의 i 번째 자릿수에 할당해야 합니다. 또한, 명시적으로 overflow 및 underflow를 방지하는 기능을 하기도 합니다.
carry의 bit를 30개 shift 함으로써 새로운 자릿수에 대한 덧셈을 지속하게 됩니다. 가장 작은 자릿수의 정수에 대한 덧셈 후 남은 자릿수에 대한 덧셈을 진행하게 됩니다.

기본 덧셈인 x_add가 정의된 다음에 다양한 덧셈에 대하여 x_add가 호출됩니다. 파서 트리의 상위 토큰이 기본토큰으로 계층화되는 구조를 차용해 덧셈을 구현한 듯합니다. 
## Sub
```c
/* Subtract the absolute values of two integers. */

static PyLongObject *
x_sub(PyLongObject *a, PyLongObject *b)
{
    Py_ssize_t size_a = _PyLong_DigitCount(a), size_b = _PyLong_DigitCount(b);
    PyLongObject *z;
    Py_ssize_t i;
    int sign = 1;
    digit borrow = 0;

    /* Ensure a is the larger of the two: */
    if (size_a &lt; size_b) {
        sign = -1;
        { PyLongObject *temp = a; a = b; b = temp; }
        { Py_ssize_t size_temp = size_a;
            size_a = size_b;
            size_b = size_temp; }
    }
    else if (size_a == size_b) {
        /* Find highest digit where a and b differ: */
        i = size_a;
        while (--i &gt;= 0 &amp;&amp; a-&gt;long_value.ob_digit[i] == b-&gt;long_value.ob_digit[i])
            ;
        if (i &lt; 0)
            return (PyLongObject *)PyLong_FromLong(0);
        if (a-&gt;long_value.ob_digit[i] &lt; b-&gt;long_value.ob_digit[i]) {
            sign = -1;
            { PyLongObject *temp = a; a = b; b = temp; }
        }
        size_a = size_b = i+1;
    }
    z = _PyLong_New(size_a);
    if (z == NULL)
        return NULL;
    for (i = 0; i &lt; size_b; ++i) {
        /* The following assumes unsigned arithmetic
           works module 2**N for some N&gt;PyLong_SHIFT. */
        borrow = a-&gt;long_value.ob_digit[i] - b-&gt;long_value.ob_digit[i] - borrow;
        z-&gt;long_value.ob_digit[i] = borrow &amp; PyLong_MASK;
        borrow &gt;&gt;= PyLong_SHIFT;
        borrow &amp;= 1; /* Keep only one sign bit */
    }
    for (; i &lt; size_a; ++i) {
        borrow = a-&gt;long_value.ob_digit[i] - borrow;
        z-&gt;long_value.ob_digit[i] = borrow &amp; PyLong_MASK;
        borrow &gt;&gt;= PyLong_SHIFT;
        borrow &amp;= 1; /* Keep only one sign bit */
    }
    assert(borrow == 0);
    if (sign &lt; 0) {
        _PyLong_FlipSign(z);
    }
    return maybe_small_long(long_normalize(z));
}
```
뺄셈은 x_sub이라는 기본 뺄셈이 정의됩니다. loop에서 뺄셈 후 i번째 자릿수에 masking 과 뺄셈의 결과의 and 연산을 할당합니다.
저는 처음에 이 부분이 헷갈렸습니다. 왜 저렇게 할당되는 것인지 이해하는 데 시간이 걸렸습니다. c언어의 정수 자료형의 최상위 bit는 sign bit입니다. 막연히, sign bit라고 알고 있었지만 , 이는 bit 연산에서 굉장히 중요한 역할을 합니다. 바로, 최상위 bit가 1이 되면 이는 $$-2^{31}$$을 의미합니다. 2의 보수나 1의 보수표현에서 최상위 bit가 1이라는 것이 그저 상징적인 의미인 줄 알았는데, 내부 동작에서는 음수를 의미하는 것이었습니다.
만약에, 자릿수의 계산값이 음수가 나온다면, 최상위 bit 2개는 1로 설정이 될 것입니다. 이를 PyLong_MASK와 and 연산을 하게 되면, 결과적으로 $$ 2^{30}$$ 을 더하게 됩니다. 즉, 위의 자릿수로부터 1을 빌려오게 되는 것과 같은 효과입니다.
그다음에, 결괏값을 30bit만큼 오른쪽으로 shift 한 다음에 sign bit가 1인지 확인을 합니다. 만약에, 1이라면 borrow를 1로 설정한 다음에 다음 자릿수 연산할 때 1을 빼주면서 시작하게 됩니다.
이렇게 되면 저희가 아는 뺄셈을 구현했다는 것을 알 수 있습니다.  

## Mul
곱셈은 karatsuba 알고리즘으로 구현이 되어 있습니다. Karatsuba 알고리즘은 큰자릿수의 곱셈에 대하여 효과적입니다. 이는 두 n자리수 곱셈에 대하여 $$O(n^{\log_{2}{3}})$$ 의 upper bound를 가집니다. 고전적인 $$ O(n^{2})$$ 의 알고리즘 보다 더 좋은 성능을 보여줍니다. 예를들어 , n=1024인경우 기존의 알고리즘은 1,048,576 회의 한자리 곱셈이 필요하지만, karatsuba의 경우 59,049 회의 한자리 곱셈이 필요하게 됩니다.  
자릿수가 작을 경우 기존의 곱셈 알고리즘을 수행하도록 합니다. 기존의 곱셈 알고리즘을 수행할 때, 두 수의 자릿수가 같다면 워털루 대학의 [참고자료](https://cacr.uwaterloo.ca/hac/about/chap14.pdf)에 있는 곱셈 알고리즘을 수행합니다. 자릿수가 다르다면 학교에서 배우는 곱셈 알고리즘을 수행합니다. 
```python
for (i = 0; i &lt; size_a; ++i) {
            twodigits carry = 0;
            twodigits f = a-&gt;long_value.ob_digit[i];
            digit *pz = z-&gt;long_value.ob_digit + i;
            digit *pb = b-&gt;long_value.ob_digit;
            digit *pbend = b-&gt;long_value.ob_digit + size_b;

            SIGCHECK({
                    Py_DECREF(z);
                    return NULL;
                });

            while (pb &lt; pbend) {
                carry += *pz + *pb++ * f;
                *pz++ = (digit)(carry &amp; PyLong_MASK);
                carry &gt;&gt;= PyLong_SHIFT;
                assert(carry &lt;= PyLong_MASK);
            }
            if (carry)
                *pz += (digit)(carry &amp; PyLong_MASK);
            assert((carry &gt;&gt; PyLong_SHIFT) == 0);
        }

``` 

여기서 f는 a의 i번째 자릿수의 값이고, pz는 곱셈 결과의 자릿수를 나타내는 포인터이고, pb는 b의 자릿수를 가리키는 포인터, pbend는 b의 가장 앞 자릿수를 가리키는 포인터입니다. 그저 c언어의 곱하기를 수행한 다음에 overflow 및 underflow를 방지하고 carry를 shift 해주는 코드입니다. `carry += *pz + *pb++ * f;` 는 z의 i번째 자릿수에 a의 i번째 자릿수 * b의 i번째 자릿수를 더합니다. inplace operator로 pb의 값을 즉, 자릿수를 증가시킵니다. `*pz++ = (digit)(carry &amp; PyLong_MASK);` 에서 PyLong_MASK로 pz i번째 자릿수에 base의 크기보다 작은 값을 할당해 줍니다. 그러면서, pz의 값, 즉 z의 자릿수를 증가시킵니다. pointer의 산술연산과 inplace operation이 결합하여 최적화가 되어있는 부분이 헷갈릴 수도 있기에 따로 설명을 해보았습니다.

## Divide
Python의 나눗셈 내부를 보면 한 자릿수의 나눗셈은 그냥 c언어의 나눗셈 연산을 사용하여 진행됩니다. 하지만, 자릿수가 커질 경우 Donald Knuth 교수님이 제안하신 Algorithm D를 사용하여 최적화 되어있습니다. 이는 The Art of Computer Programming, Vol.2 4.3.1 chapter에 실려있습니다. 이에 대해서는 따로 소개하지 않도록 하겠습니다. 여러 나눗셈 토큰들이 기본 연산인 x_divrem이라는 활용하는데, x_divrem은 내부적으로 Algorithm D로 구성돼 있다고 알고 있으면 좋을 거 같습니다.
그뿐만 아니라, Modular operator와 floor operation 그리고 몫과 나머지를 전부 반환하는 operation도 구현이 되어있는데, single bit의 경우 c언어의 기본연산을 활용하여 구현되어 있고, 긴 자릿수의 경우 x_divrem을 사용하여 구현되었습니다.

## 256까지의 정수

간단한 얘기지만, 256까지의 정수는 미리 메모리에 caching이 되어 있습니다. 따라서, 매번 operation을 할 때, object를 생성하게 되는데 256까지의 정수는 memory에 있는 값을 reference 하기에 object가 새로 생성되지 않습니다.
## Conclusion
여태까지, +,-,*,/,%,// 등등의 operator를 사용하면서 실제 연산이 어떻게 구현되는지는 관심이 없었습니다. 실제로 내부 구현을 보면서 2의 보수표현이 왜 효과적인지 깊이 있게 알게 되었습니다. 정수는 32bit의 int로 arbitrary precision을 지원하지만, float의 경우 c의 double type을 그대로 활용하기에 연산이 상대적으로 간단하였습니다. divide,mul을 제외한 기본연산들은 자릿수를 넘기는 간단한 방식의 연산을 지원하지만, 이 과정에서 사용된 여러 idea 등을 low-level에서 어떻게 구현되는지 알게 되었습니다. Computer Architecture의 공부를 다시 깊이 있게 해야 함을 느끼게 되었습니다. 
## References

https://www.codementor.io/@arpitbhayani/how-python-implements-super-long-integers-12icwon5vk  


https://rushter.com/blog/python-integer-implementation/  


https://github.com/python/cpython/pull/102464  


https://github.com/python/cpython/blob/main/Include/cpython/longintrepr.h#L89  


https://github.com/python/cpython/issues/101291  


https://github.com/python/cpython/blob/main/Include/cpython/longintrepr.h#L47C1-L55C27


https://ko.wikipedia.org/wiki/%EC%B9%B4%EB%9D%BC%EC%B6%94%EB%B0%94_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98</content><author><name>Choi Woongjoon</name></author><category term="Python" /><category term="Python" /><category term="Object" /><category term="Builtin" /><summary type="html">Python Intger Internal</summary></entry><entry><title type="html">Train,Dev,Test의 error를 어떻게 해석해야 할까요?</title><link href="http://localhost:4000/dls_c3/What-to-do-we-see-error/" rel="alternate" type="text/html" title="Train,Dev,Test의 error를 어떻게 해석해야 할까요?" /><published>2024-01-11T00:00:00+09:00</published><updated>2024-01-11T00:00:00+09:00</updated><id>http://localhost:4000/dls_c3/What-to-do-we-see-error</id><content type="html" xml:base="http://localhost:4000/dls_c3/What-to-do-we-see-error/">프로젝트에서 Machine Learning Model을 사용하기로 했습니다. 그러면, Model을 개발할 때, 어떤 Model을 고르고, 데이터를 증강하는지, 어떤 알고리즘을 쓰는지 등등이 중요해집니다. 이는 모델이 Over fit인지, Variance가 높은지 판단해야 좋은 선택을 할 수 있습니다.Andrew 교수님의 DeepLearning Specialization에서 이에 대한 내용을 다루었고 이를 정리했습니다.  

# Error-rate를 확인하면 어떻게 해야할까?
Error-rate를 train,dev, test에 대해서 logging 할 것입니다. 이 log 값들을 가지고 어떻게 해야 할지 결정하기 위해서는 몇 가지 용어들을 정의해야 합니다.  

## Term
여기서는 human-level performance와 avoidable bias라는 용어의 정의와 이에 대해 간략한 설명을 하겠습니다.

### Human-level performance
![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217819&amp;authkey=%21AFm_FOTf9RHr9A4&amp;width=611&amp;height=351)

Machine Learning의 성능은 시간이 지나면서 사람의 능력을 뛰어넘게 되었습니다. 하지만, 이론상 최고 성능에는 도달하지 못하고 계속 근접하게 됩니다. 이론상 최고치를 Bayes optimal error라고 합니다. 여기서, 사람의 능력을 human level performance라고 합니다. Bayes error는 이론상의 최대치이고 계산할 수 있지만 조건에 따라 계산이 매우 복잡하여 수치적으로 근사하는 것이 최선일 수 있습니다. 즉, ***언제나 정확한 Bayes error 값을 알 수 없습니다.*** Bayes error를 human level performance가 넘을 수는 없지만, human level performance는 Bayes error에 상당히 근접해 있습니다. 따라서, human level performance를 Bayes error의 approximation이라 여기고 Bayes error 대신 사용하게 됩니다. 

머신러닝 에서는 human level performance에 도달하기 전까지는 모델의 performance를 빠르게 올릴 수 있습니다. 왜냐하면, bias, variance를 설정할 수 있으므로 목표를 어떻게 잡아야 할지 명확히 알 수 있습니다. 하지만, human level performance를 넘게 된다면 performance를 끌어올리기 어려워집니다. Bayes error를 정확히 알 수 없기에 목표 지점을 정확히 잡을 수 없습니다. 특히, Online Ads, Recommendation, Loan Approval 같은 **Structured Data** 을 활용하는 Model은 이미 사람을 뛰어넘었다고 알려져 있습니다. 이러면, bias, variance를 활용한 방법이 아닌 다른 방법들을 마련해야 합니다. 하지만, 시각, 청각, 사고 같은 **자연적 인지** 에서는 아직 인간을 딥러닝이 따라잡지 못하고 있습니다. 따라서, human-level performance를 아는 것이 중요하다고 할 수 있습니다.  

### Avoidable bias
avoidable bias는 **Bayes error approximation 과 training error 간의 차이**입니다. 여기서, approximation은 human level performance가 됩니다. 이 avoidable bias를 bias로 설정하고,  variance는 human level performance와 dev error와의 차이로 설정해서
모델의 performance를 높이기 위한 전략을 세우게 됩니다. 이때, avoidable bias는 0 이상이어야 하므로, training error의 upper bound가 human level performance임을 내포하고 있습니다.  

## bias reduction or variance reduction ?
  
|error type|Approach|
|-------------|-----------------------------------------|
|High Avoidable Bias| - Traing Bigger Model  &lt;br/&gt; - Train Longer  &lt;br/&gt; - Better Optimization Algorithm  &lt;br/&gt; - Architecture,hyperparameter search|
|High Variance| - More Data &lt;br/&gt; - regularization &lt;br/&gt; - Architecture,hyperparameter search|  

Avoidable bias가 높다는 것은 모델이 Training data를 잘 학습하지 못한다는 뜻이므로, parameter가 더 많은 모델을 사용하거나 훈련을 더 길게 하거나 optimization 알고리즘이 다른 걸 사용할 수 있습니다.
Variance가 높다는 것은 모델이 일반화를 못했다는 뜻이므로, 더 많은 데이터를 수집하거나 Regularization 기법을 사용할 수 있습니다.  

# Error를 분석하자
bias문제인지 variance 문제인지  error-rate 를 통해 판단이 되었습니다. 그렇다면, 구체적인 error의 내용을 분석해서 구체적인 전략을 세워야 합니다. 

## error-label check
dev, test, train의 error를 사람이 확인해서 구체적인 insight를 얻을 수 있습니다. 예를 들어, 동물을 분류하는 multi classifier 문제의 경우에 아래와 같은 식으로 어떻게 잘못 분류했는지를 검사할 수 있습니다.  

|Image|Dog|Cat|....|Comments|
|-------------|-------------|-------------|-------------|-------------|
|1| |$$\checkmark$$ | |Pitball|
|2|$$\checkmark$$ | | |Lion|
|...| | | | | 

체크를 하다 보면, labeling이 잘못되어 있는 경우가 있을 수 있습니다. 이 경우에는 label miss라는 마크를 따로 달아두는 것이 좋다고 합니다.  

|Image|Dog|Cat|....|miss label|Comments|
|-------------|-------------|-------------|-------------|-------------|-------------|
|1| |$$\checkmark$$ | ||Pitball|
|2|$$\checkmark$$ | | ||Lion|
|3| | | | $$\checkmark$$|miss labeling|
|...| | | | ||    

이러한 analysis를 통해 insight를 얻게 되면, 바로 성능향상 작업에 들어가서는 안 됩니다. 특정 error나 mislabeling이 나왔다고 해서 전부 고치는 것이 항상 정답은 아닙니다. 예를 들어, dog를 잘못 분류하는 예제가 10개가 나왔고, dog를 잘 분류하도록 알고리즘을 설계하는 작업에 착수했습니다. 하지만,  이 예제가 전체 오답률의 1퍼센트라면 이는 미미한 성능향상을 끌어낼 것입니다. 또, labeling을 잘못되어 있어서 이를 수정하는 데 자원을 소모했습니다. 그렇지만, 이 비율이 2퍼센트 정도라면 큰 성능향상을 끌어내지 않을 것입니다.
만약에, 특정 예제나 miss labeling이 비율이 오답의 30%~40%라면 유의미한 성능향상을 보일 것입니다.
error label을 검사할시 몇 가지 tip이 있습니다.  

error label을 사람이 체크하고 수정할 시, dev set에 했던 process를 test set에서도 해야 합니다. machine learning model은 dev, test가 같은 distribution에서의 data라 예상하고 model의 성능을 평가합니다. 따라서, dev에서도 일반화가 된다면 test에서도 일반화가 되어야 합니다. dev와 test가 같은 distribution을 가져야 하므로, dev에서 label을 고쳤다면, test에서도 label을 고쳐줍니다.  

error를 확인할 때 맞춘 것도 보는 것이 도움이 됩니다. Model이 운이 좋아서 정답을 맞힌 가능성이 있기 때문입니다. 만약에, 틀린 예제만을 점검할 시, 모델의 error 추정치가 과대평가 될 수 있습니다. 하지만, 이는  Model의 성능이 좋으면 좋을수록 하기 어렵습니다. 예를 들어, 모델의 정확도가 98퍼센트이고 error 비율이 2퍼센트라면면 98퍼센트의 데이터를 보는 것은 많은 자원이 소모되기 때문입니다. 

실제로는, training data의 error를 확인하는 것이 정석이지만, dev ,test에 비해 data의 size가 상당히 크기 때문에 자원이 상당히 많이 소모됩니다. 딥러닝 알고리즘은 random 한 error에 robust 하므로 training data의 random 한 error에 대해서는 영향을 거의 받지 않을 것입니다. 

## Build System First
실제로 ML project를 임할 때에는 error analysis에 집중하기 보다는 bias, variance를 통해 model의 performance를 향상하게 시키는 system을 구축하는 것이 중요하다고 합니다. error analysis나 distribution 차이는 그다음에 해결해도 괜찮다고 합니다. 우선은, model performance를 향상하게 시키는 system을 구현하는 것이 훨씬 중요하다고 합니다.  

## Mismatched data distribution
위의 Error Analysis 과정을 거치면서, 특정 label이나 mislabel 문제가 아님이 밝혀질 수 있습니다. Train 과 dev, test의 distribution 차이에서 오는 variance의 문제일 수도 있습니다. 

### Distribution Eqaulity
예를 들어, 모바일 앱에서 구동하는 ML application을 개발한다고 하겠습니다. Train Data 약 20만 개를 web에서 수집하고, dev, test에는 mobile app에서 수집한 data 1만 개를 각각 5천개씩 나누어서 사용했습니다. 이렇게 되면, train과 dev, test 간의 distribution의 차이로 문제가 발생할 수 있습니다. web에서의 image data는 화질이 좋지만,, mobile app의 image data는 화질이 좋지 않을 가능성이 있습니다.  

이때 , train, dev,test data를 단순하게 shuffle 해서 같은 distribution으로 만들어 주는 방법을 사용할 수 있습니다. 하지만, 이 새로운 data는 mobile data 반영률이 약 4.7퍼센트 정도밖에 되질 않을 것입니다. ML model이 학습하고자 하는 distribution은 mobile의 distribution인데, model은 전혀 다른 distribution을 target으로 삼고 있는 것입니다.
대신에, dev, test를 각각 2500개 정도로 설정하고 5천 개를 train에 포함하므로 train의 distribution을 dev, test에 더 가깝게 만드는 방법을 사용할 수 있습니다.  하지만, 여전히 train과 dev, test의 distribution은 다릅니다. 

어떤 방법을 적용할지는 팀의 상황과 project의 제한조건 등에 따라서 다를 것이므로 , 정답이 없다고 여겨집니다. 하지만, Andrew 교수님은 후자의 방법이 장기적으로 더 좋은 효과를 보일 것이라 얘기하십니다.   

### Data Augmentation and Collect Data
더 많은 data를 확보하는 것도 좋은 방법이 될 수 있습니다. 이때, data augmentation과 collect data를 고려하게 됩니다.
collect data는 말 그대로 data를 추가로 수집을 하는 것입니다. train에 mobile에서의 data가 부족하다면, mobile data를 추가로 수집해서 train data에 포함할 수 있습니다.
Data Augmentation은 기존에 가지고 있는 data로 새로운 data를 합성해 내는 것입니다. 예를 들어, 사람의 목소리와 차의 소음 소리를 결합해 차 속에서 말하는 사람의 목소리를 만들 수 있습니다. 아니면, 기존의 자동차 사진으로 새로운 자동차 사진을 생성해 낼 수 있습니다. 하지만, data augmentation 시 주의할 점이 있습니다. **적은 data로 augmentation 시 train은 여전히 sample space의 작은 subset일 가능성이 있다**는 것입니다. 차의 소음 소리 data가 만 시간 정도가 있고, 사람의 목소리 data가 100만 시간이 있다고 가정하겠습니다. 여기서, 사용할 수 있는 방법은 차의 소음 소리를 100번 반복해서 사람의 목소리와 합성하는 것입니다. 사람의 귀에는 다 다른 소음 data로 들리지만, computer 입장에서는 전부 같은 소음 data로 보일 수 있습니다. 또한, 20개의 차 이미지로 새로운 차 이미지를 만들어 냈다고 했을 때, 사람의 눈에는 달라 보이지만 computer 입장에서는 같은 차 이미지일 수 있습니다.  small subset만을 학습하게 된다면, model을 sample space의 일부에 overfit이 될 것입니다.  
### Train-dev 
Train data와 dev, test의 data가 서로 다른 distribution인지 아닌지 모를 수도 있습니다. 이럴 때는, train-dev라는 새로운 data set을 만듦으로써 확인할 수 있습니다. train data에서 무작위로 train-dev를 sampling 하므로 train-dev와 train은 같은 distribution을 갖게 됩니다. 따라서, 이 model이 unseen data에 대해서 예측을 잘하는지를 판단할 수 있게 됩니다. 

# Decision Making in General Foramt
  
|Error Type|Comapre|
|-------------|-----------|
|high avoidable bias|human-level vs train error|
|high variance|train error vs train-dev error|
|data mismatch|train-dev error vs dev/test error|  

위에서 작성된 decision 전략에서 train-dev error와의 차이가 추가되었습니다.  알고리즘이 일반화가 잘 되는지를 dev, test가 아닌 train-dev와 비교하는 것이 좀 더 일반화된 형태의 decision making이라 볼 수 있겠습니다. 


# Conclusion 

ML project team에서 ML의 새로운 model의 performance를 올릴 때는 아래와 같은 순서를 따른다고 볼 수 있습니다.

1. bias, variance 값에 따라 approach를 적용할 수 있는 system을 만든다.
2. system build 후 error analysis를 통해 distribution mismatch인지 아닌지를 점검한다.
3. distribution이 mismatch가 아니라면 error case 중 비율이 높은 것을 우선시한다.



# Reference 

[DeepLearning Specialization](https://www.coursera.org/learn/machine-learning-projects/home/week/1)</content><author><name>Choi Woongjoon</name></author><category term="DLS_C3" /><category term="Machine Learning" /><category term="Coursera" /><category term="deep learning" /><summary type="html">ML Project structing</summary></entry><entry><title type="html">임의의 숫자의 parameter를 가진 FeedForward Network의 일반항을 정의하고 vectorize하는 과정을 수식으로 도출해보자</title><link href="http://localhost:4000/dlarchitecture/Feed-Forward-Network/" rel="alternate" type="text/html" title="임의의 숫자의 parameter를 가진 FeedForward Network의 일반항을 정의하고 vectorize하는 과정을 수식으로 도출해보자" /><published>2023-12-30T00:00:00+09:00</published><updated>2023-12-30T00:00:00+09:00</updated><id>http://localhost:4000/dlarchitecture/Feed-Forward-Network</id><content type="html" xml:base="http://localhost:4000/dlarchitecture/Feed-Forward-Network/">## Why we need understand Neural Network in Mathematical view?
FeedForward Network는 가장 기본적인 형태의 neural net입니다. 이는 노드에 weight matrix를 곱하고 bias를 더 해줌으로써 구현됩니다. neural net을 수식으로 이해함으로써 neural net에 대한 이해도가 올라가기 때문에 수학적으로 이해하는 것이 딥러닝 엔지니어의 역량을 기르는데 많은 도움이 된다고 여겨집니다. 이 글은 임의의 layer의 node의 일반항을 도출하여 vectorize하는 과정을 수식으로 도출할 것입니다 .
## Term Definition
여기서의 Term에 관한 Symbol이나 Notation 방식은 Andrew 교수님의 DeepLearning 강의를 참고하였습니다.  

|기호|설명|
|-------------------------------|-----------------------------------------------------------------------------------|
|$$l$$| $$l $$번째  layer  . $$ l $$ =   0, ... , L  은 weights와 bias를 가지는  layer의 번호를 의미한다.|
|$$n^{[l]}$$| $$ l $$ 번째 layer의 node의 개수를 의미합니다.|
|$$j$$|$$j  = 0,..., n^{[l]}$$|
|$$k$$|$$k = 0, .... n^{[l-1]} $$|
|$$m$$|$$m$$ 은 training step에서의 batch size 입니다.|
|$$i$$|$$i = 0,..... m$$|
|$$w_{j,k}^{[l]}$$| $$l $$ 번째 layer의 weight $$ W^{[l]} $$ , $$ W^{[l]} \in \mathbb{R}^{n^{[l]} \times n^{[l-1]} } $$ . $$ W^{[l]} $$ 의 $$(j,k) $$ 원소를 의미한다.|
|$$z_{j,i}^{[l]}$$| $$l$$ 번째 layer의 bias를 더한 output의 $$(j,i)$$ 성분입니다 . |
|$$a_{j,i}^{[l]}$$|$$l$$ 번째 layer의 activation의 $$(i,j) $$성분입니다 .|
|$$b^{[l]}$$|$$l$$ 번쨰 layer의 bias입니다.$$ b^{[l]} \in \mathbb{R}^{n^{[l]}  } $$ |
|$$g_{j}^{[l]}$$| $$l$$ 번째 layer activation function $$g_{j}^{[l]} : \mathbb{R}^{n^{[l]}} \rightarrow \mathbb{R}^{n^{[l]}} $$  , $$g_{j}^{[l]} \in \mathbb{R}^{n^{[l]}  } $$|  

## Explanation in Mathematical View

### $${Z}^{[l]}$$ 의 vectorization 
![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217803&amp;authkey=%21AG3PCmGXC76EdXA&amp;width=1121&amp;height=1233)


다른 교육자료들을 보면 쉽게 설명하기 위해서 3개의 node로 한정짓거나 하는 방식으로 설명을 하게 됩니다. 하지만, 여기서는 일반식을 정의하기 위해서 $$ n^{[l-1]}$$개의 node에서  $$ n^{[l]}$$개의 node로 변환시키는 $$ l$$번째 layer에  대해서 설명을 하겠습니다. (bias는 그림에서만 생략하였습니다 . ) . 위의 그림은 $$ l$$번째 layer 를 나타낸 그림입니다. 동그라미가 node이고 연결선이 weight입니다. notation은 [Definition](#term-definition)을 참조하시면됩니다.

여기서 , $$z_{k,i}^{[l]}$$ 에는 $$ n^{[l-1]} $$ 개의 node가 연결되어 있습니다.    
따라서 ,   

$$ 
\begin{equation}
z_{j,i}^{[l]} = \sum_{k=0}^{n^{[l-1]}}  w_{j,k}^{[l]} \cdot a_{k,i}^{[l-1]} + b_{j}^{[l]} 
\end{equation}
$$    

위 수식을 `(1)` 이라 하겠습니다.  

vector space는 다음과 같이 정의됩니다.  $$ \vec{a}_{:, i}^{[l-1]} \in \mathbb{R}^ {n \times {n^{[l-1]}} }, \vec{w}_{j, :}^{[l]} \in \mathbb{R}^ {n \times {n^{[l-1]}}}  $$  .  

딥러닝에서는 이러한 multiplication을 sequential하게 하는것이 아닌 parallell 하게 진행합니다.(ex.Numpy) 따라서, 우리는 `(1)` 을 vectorization 해야 합니다 .  위 식은 sum을 나타내지만 , 이는 vector $$ w_{j,:}^{[l]} $$ 와 vector $$ a_{:,i}^{[l-1]}$$  의 multiplication이라 볼 수 있습니다. 위 식에서 변수 j의 범위는 $$ 0&lt;= j &lt;=n^{[l]} $$ 입니다.  따라서 , 이를 확장하면 아래와 같이 vectorize할 수 있습니다.


$$
\begin{align*}
\begin{bmatrix}
z_{1, i}^{[l]} \\
\vdots \\
z_{j, i}^{[l]} \\
\vdots \\
z_{n^{[l]}, i}^{[l]}
\end{bmatrix} &amp;=
\begin{bmatrix}
w_{1, 1}^{[l]} &amp; \dots &amp; w_{1, k}^{[l]} &amp; \dots &amp; w_{1, n^{[l - 1]}}^{[l]} \\
\vdots &amp; \ddots &amp; \vdots &amp; \ddots &amp; \vdots \\
w_{j, 1}^{[l]} &amp; \dots &amp; w_{j, k}^{[l]} &amp; \dots &amp; w_{j, n^{[l - 1]}}^{[l]} \\
\vdots &amp; \ddots &amp; \vdots &amp; \ddots &amp; \vdots \\
w_{n^{[l]}, 1}^{[l]} &amp; \dots &amp; w_{n^{[l]}, k}^{[l]} &amp; \dots &amp; w_{n^{[l]}, n^{[l - 1]}}^{[l]}
\end{bmatrix}
\begin{bmatrix}
a_{1, i}^{[l - 1]} \\
\vdots \\
a_{k, i}^{[l - 1]} \\
\vdots \\
a_{n^{[l - 1]}, i}^{[l - 1]}
\end{bmatrix} +
\begin{bmatrix}
b_1^{[l]} \\
\vdots \\
b_j^{[l]} \\
\vdots \\
b_{n^{[l]}}^{[l]}
\end{bmatrix},
\end{align*}
$$  

이를 수식으로 표현하면 다음과 같습니다.  

$$\vec{z}_{:, i}^{[l]} = \vec{W}^{[l]} \vec{a}_{:, i}^{[l - 1]} + \vec{b}^{[l]} $$ 

vector space는 다음과 같이 정의됩니다 .$$\vec{z}_{:, i}^{[l]} \in \mathbb{R}^{ {n^{[l]}}} , \vec{W}^{[l]} \in \mathbb{R}^{n^{[l]} \times n^{[l - 1]}}  , \vec{b}^{[l]} \in \mathbb{R}^{ {n^{[l]}}} , \vec{a}_{:, i}^{[l - 1]} \in \mathbb{R}^{ {n^{[l - 1]}}}$$

이는 1개의 training data에 대한  math expression입니다. 이를 이제 $$ m $$개의 batch data의 size로 확장하여 vectorize를 해보겠습니다.   

$$
\begin{align}
\vec{Z}^{[l]} &amp;=
\begin{bmatrix}
\vec{z}_{:, 1}^{[l]} &amp; \dots &amp; \vec{z}_{:, i}^{[l]} &amp; \dots &amp; \vec{z}_{:, m}^{[l]}
\end{bmatrix}  \\
&amp;= \vec{W}^{[l]}
\begin{bmatrix}
\vec{a}_{:, 1}^{[l - 1]} &amp; \dots &amp; \vec{a}_{:, i}^{[l - 1]} &amp; \dots &amp; \vec{a}_{:, m}^{[l - 1]}
\end{bmatrix} +
\begin{bmatrix}
\vec{b}^{[l]} &amp; \dots &amp; \vec{b}^{[l]} &amp; \dots &amp; \vec{b}^{[l]}
\end{bmatrix} \notag \\
&amp;= \vec{W}^{[l]} \vec{A}^{[l - 1]} + broadcast(\vec{b}^{[l]}), \notag \\
\end{align}
$$  

vector space는 다음과 같이 정의됩니다 .$$ \vec{Z}^{[l]} \in \mathbb{R}^{n^{[l]} \times m} , \vec{A}^{[l - 1]} \in \mathbb{R}^{n^{[l - 1]} \times m}$$


### $${A}^{[l]}$$ 의 vectorization
![image](https://onedrive.live.com/embed?resid=7E81BBCD99889380%217804&amp;authkey=%21AF5RN-qLjiNzdI4&amp;height=1121&amp;width=1233)  

위의 그림은 $$Z^{[l]}$$ 을 activation function $$g^{[l]} $$ 에 parameter 로 넘겨주는 그림입니다. $$Z^{[l]}$$ 의 모든 node가 $${A}^{[l]}$$의 각 node에 전부 연결되어 있습니다. $$g^{[l]} $$ 이 아직 확정이 되지 않았기에 그렇습니다. 보통은 RELU를 사용하게 되어 1 대 1 mapping 관계가 되지만, softmax를 사용하게 된다면 $$ n^{[l]} $$ 대 1 mapping 관계가 될 것입니다. notation은 [Definition](#term-definition)을 참조하시면됩니다.  

아래와 같은 식으로 표현할 수 있습니다.  

$$ 
\begin{equation}
a_{j, i}^{[l]} = g_j^{[l]}(z_{1, i}^{[l]}, \dots, z_{j, i}^{[l]}, \dots, z_{n^{[l]}, i}^{[l]}). 
\end{equation}
$$  

위 수식을 `(2)` 이라 하겠습니다.  

마찬가지로, sequential하게 하는것이 아닌 parallell 하게 진행되기 때문에 `(2)` 를 vectorize 해보도록 하겠습니다.    

$$
\begin{align*}
\begin{bmatrix}
a_{1, i}^{[l]} \\
\vdots \\
a_{j, i}^{[l]} \\
\vdots \\
a_{n^{[l]}, i}^{[l]}
\end{bmatrix} &amp;=
\begin{bmatrix}
g_1^{[l]}(z_{1, i}^{[l]}, \dots, z_{j, i}^{[l]}, \dots, z_{n^{[l]}, i}^{[l]}) \\
\vdots \\
g_j^{[l]}(z_{1, i}^{[l]}, \dots, z_{j, i}^{[l]}, \dots, z_{n^{[l]}, i}^{[l]}) \\
\vdots \\
g_{n^{[l]}}^{[l]}(z_{1, i}^{[l]}, \dots, z_{j, i}^{[l]}, \dots, z_{n^{[l]}, i}^{[l]}) \\
\end{bmatrix}
\end{align*}
$$
  
이를 수식으로 표현하면   

$$
\vec{a}_{:, i}^{[l]} = \vec{g}^{[l]}(\vec{z}_{:, i}^{[l]})
$$  

vector space는 다음과 같이 정의됩니다 .$$ \vec{a}_{:, i}^{[l]} \in R^{n^{[l]}} $$  

위의 수식은  전체 activation 중 1개의 node를 의미합니다. 이를 전체 activation에 대해 확장해보도록 하겠습니다 . 

$$
\vec{A}^{[l]} =
\begin{bmatrix}
\vec{a}_{:, 1}^{[l]} &amp; \dots &amp; \vec{a}_{:, i}^{[l]} &amp; \dots &amp; \vec{a}_{:, m}^{[l]}
\end{bmatrix},
$$  

vector space는 다음과 같이 정의됩니다. $$ \vec{A}^{[l]} \in R^{n^{[l]} \times m} $$  

## Conclusion

임의의 layer의 vectorize 과정을 수학적으로 직접 도출해보았습니다. 아래와 같은 이유로 도움이 될 것이라 여겨집니다. 

1. neural net에 대한 이해도가 올라간다.
neural net의 작동 원리를 깊게 이해하면, 모델의 성능을 향상시키고 문제를 해결하는 데 도움이 됩니다. 일반항을 도출하면 neural net의 내부 작동 방식을 더 잘 이해할 수 있습니다

2. neural net이 어떻게 계산을 최적화 하는지 이해
vectorization 과정을 수식으로 도출하면, 어떻게 최적화할 수 있는지에 대한 통찰력을 얻을 수 있습니다.

3. 문제 해결 능력 
벡터화 과정을 수식으로 도출하면, 모델이 예상대로 작동하지 않을 때 문제를 진단하고 해결하는 데 도움이 될 것입니다.. 이는 디버깅 및 최적화 과정에서 매우 유용합니다.\

4. 커뮤니케이션 능력 향상
이러한 수식을 도출하고 이해하는 능력은 다른 엔지니어, 연구원, 이해관계자와의 커뮤니케이션에서 중요합니다. 이를 통해 복잡한 개념을 명확하게 전달하고, 팀의 협업을 촉진할 수 있습니다.

5. 가장 기본이다.
feedforward network는 가장 기본적인 형태이기에 vectorize 과정을 수식으로 도출을 해본다면, 다른 neural net을 도출해내는 데에도 도움이 될 것입니다. 뿐만 아니라, 다른  neural net 모델들을 분해해보면 feedforward 가 사용되어지는 경우가 많습니다. 




## Reference

1.  [feedforward-neural-networks-part-1/journalsim From Jonas Lalin ](https://jonaslalin.com/2021/12/10/feedforward-neural-networks-part-1/)    

2. [wikiepdia](https://en.wikipedia.org/wiki/Feedforward_neural_network)</content><author><name>Choi Woongjoon</name></author><category term="DLArchitecture" /><category term="Machine Learning" /><category term="deep learning" /><summary type="html">Mathematical view</summary></entry><entry><title type="html">The Phyiscal Layer</title><link href="http://localhost:4000/network/The-Physical-Layer/" rel="alternate" type="text/html" title="The Phyiscal Layer" /><published>2022-10-03T00:00:00+09:00</published><updated>2022-10-03T00:00:00+09:00</updated><id>http://localhost:4000/network/The-Physical-Layer</id><content type="html" xml:base="http://localhost:4000/network/The-Physical-Layer/">예전 Post에서 TCP-IP Model에 대해 설명을 한 적이 있습니다. TCP-IP Model은 5개의 layer로 이루어져 있는데, 오늘은 가장 아래 layer인 Physical Layer Model에 대해서 설명해보도록 하겠습니다. 

# Physical Layer?

![image](https://user-images.githubusercontent.com/50165842/192401951-1c3511fd-0043-4d22-84a4-ccca355c97fc.png)

Physical Layer란 여러 device에서 다른 Network로 Bit라는 정보를 보내게 됩니다. Bit는 computer가 이해할 수 있는 data 의 representation입니다. 0,1의 값을 가지고 있습니다.   



구리 네트워크 케이블에 Modulation이라는 과정을 거쳐서 bit를 만들어 보내게 됩니다. Modulation이란 cable을 따라 움직이는 전하의 전압을 다르게 하는것을 의미합니다. 
![image](https://user-images.githubusercontent.com/50165842/192905671-59927d83-99a7-4192-a317-c08583b6b058.png)


Computer Networking에서 이러한 Modulation을 line coding이라 부릅니다. 현대 networking에서는 10 기가비트 네트워크라는 단어가 많이 등장하는데 이는 100억개의 bit(0,1)을 각 cable마다 1초에 처리한다는 의미입니다. 


# Twisted Pair Cabling

![image](https://user-images.githubusercontent.com/50165842/192906277-22635c2f-4c75-4f5f-9ba2-06b0fc052f38.png)

twisted pair란 구리선이 꼬아져있음을 의미합니다. 꼬아져 있는 cable pair로 이루어져 있어서 twisted pair cable이라 합니다. 이렇게 cable을 꼬아두면 , 전자기간섭 , 즉 crosstalk을 줄여줍니다.  
예를 들어, cat6 cable은 8개의 wire,즉 4 pair를 사용합니다. 전송기술에 따라서  몇개의 pair를 사용할 지 결정합니다.
# Duplexing

근대의 네트워킹에서 cable은 duplex communication이나 simplex communication을 사용합니다.    
![image](https://user-images.githubusercontent.com/50165842/192907374-7139d5a2-fa5c-4ab9-9c73-eb429b4f7593.png)  

simplex는 정보를 한 방향으로만 전송하는 communication 방식을 의미합니다.그림과 같이 한 쪽의 device가 일방적으로 수신하거나 송신하는것을 볼 수 있습니다. 대표적인 예시로는 , 라디오나 TV가 있습니다. 방송국에서 전파를 송신하고 , 청자는 그 전파를 수신하기만 합니다.  
![image](https://user-images.githubusercontent.com/50165842/193703834-b4a8bc16-a6b1-45cb-93ed-7761ef8dc4c8.png)  

Duplex는 Client와 Server가 양방향으로 communication을 할 수 있는 방식입니다. 그렇다면 , 이것이 어떻게 가능한 것일까요?  
cable은 여러개의 pair로 이루어져 있는데 ,각 pair를 한 방향으로만 미리 예약을 해두는 것입니다. 정확히 동시에 양방향 communication이 가능하다면 , 이를 full duplex라고 부릅니다.

![image](https://user-images.githubusercontent.com/50165842/192907219-b76b3246-9525-473f-a3f5-52338320cef1.png)

만약에 Network에 문제가 생긴다면, Network는 link가 degrade 되고 , half-duplex communication을 한다고 보고합니다.  
이 때, Network는 양방향으로 communication이 가능하지만, 한번에 한방향으로만 가능합니다. 

# Network Ports and panel

Twisted Pair network cable에는 끝에 Plug가 있습니다. 

![image](https://user-images.githubusercontent.com/50165842/193705135-31a0b36a-c130-4664-861c-a2d8071ecb6e.png)  

가장 대중적인 plug는 RJ45 plug(Registered Jack 45)가 있습니다.  
![image](https://user-images.githubusercontent.com/50165842/193705565-1e8ffa88-ec48-40a4-9dbb-c64140880ae7.png)  
![image](https://user-images.githubusercontent.com/50165842/193705655-9bafd997-c574-4eb7-ba11-c963cbcda4dc.png)  
저번에 설명했던, Switch에는 여러개의 port가 있는반면, Server나 Desktop에는 1 개나 2개의 port가 달려있습니다.  
![image](https://user-images.githubusercontent.com/50165842/193705381-c4cb44c5-1763-43dd-80cb-555e3f94757c.png)  


모든 네트워크 port는 link led, activity led라는 2개의 port를 가지고 있습니다. LinkLed는 두 Device가 잘  연결되면 전원이 켜집니다. activityLed는 data가 활발하게 전송되면 ,  LED가 깜빡입니다.   
요즘은, 컴퓨터 네트워크가 워낙 빨라서 ,Activity Led는 실제로 traffic이 있는지 없는지 외에는 의미하지 않습니다.  

![image](https://user-images.githubusercontent.com/50165842/193705887-78fbb6cf-3513-46a8-a44d-f4fd93120f73.png)
가끔씩, 책상 아래에 network port가 붙어있는 경우가 있습니다. 이 포트들은 네트워크 케이블을 통해서 , 벽을 넘어가서 patch-panel에 도달하게 됩니다. patch-panel에는 많은 port들이 잇지만, 그저 port의 container일 뿐입니다. 이 patch panel로 부터 나온 cable은 switch나 router나 computer로 향하게 됩니다.

# References

[Google-IT-support][Google-It-support]

[Google-It-support]: &quot;https://www.coursera.org/learn/computer-networking/lecture/Nihjd/moving-bits-across-the-wire&quot; 

[Twisted-pairwiki][Twisted-pairwiki]

[Twisted-pairwiki]: &quot;https://en.wikipedia.org/wiki/Twisted_pair&quot;


[Simplex][Simplex]

[Simplex]: &quot;https://en.wikipedia.org/wiki/Simplex_communication&quot;

[Duplex][Duplex]

[Duplex]: &quot;https://en.wikipedia.org/wiki/Duplex_(telecommunications)&quot;</content><author><name>Choi Woongjoon</name></author><category term="Network" /><category term="SoftwareEngineering" /><category term="Network" /><category term="TCPIP" /><summary type="html">TCP 5 layer model-phyiscal</summary></entry><entry><title type="html">Pytorch data api : Multiprocessing</title><link href="http://localhost:4000/pytorch/Single-and-MultiProcessing/" rel="alternate" type="text/html" title="Pytorch data api : Multiprocessing" /><published>2022-09-16T00:00:00+09:00</published><updated>2022-09-16T00:00:00+09:00</updated><id>http://localhost:4000/pytorch/Single-and-MultiProcessing</id><content type="html" xml:base="http://localhost:4000/pytorch/Single-and-MultiProcessing/">Pytorch에서 DataLoading을 할 때 DataLoader라는 class를 사용하는데 , 이 때 Data를 단일 Process내에서 loading 할수도 있고, parallelize해서 loading을 할 수도 있다.

# Default Option
DataLoader는 Single Process data loading이 default option입니다 .

Python Process는 GIL(Global Interpretatoin Lock)이 Python Code를 thread로 parallelize하는 것을 막습니다. 따라서, data loading에서 computation을 1개의 process가 blocking 하는것을 방지하기 위해서 ,Pytorch는 'num_workers' 라는 argument를 양의 정수로 설정하여 multi-process data loading으로 쉽게 전환 시킵니다. 


# Single Processing

data fetching이 같은 process내에서 이루어집니다. 즉, 1개의 process가 computing을 block하는 상태입니다. 
이 방법은 resource가 제한이 되거나 , 전체 memory 에 data를 올릴 수 있을만큼 작다면 , 선호되는 방법입니다.  
또한, 이 방법의 장점으로는 error tracing이 쉽다는 것입니다. 이에 대해서는, Multi Processing에서 자세히 알아보도록 하겠습니다.

# Multi Processing

Dataloader에서는 num_workers라는 argument를 설정할 수 있습니다. 

1. 'num_workers' = 0 
   + data loading이 main process에서 이루어집니다.
2. 'num_workers' &gt; 0 
   + multi-process data loading 이 활성화되고 , 지정한 숫자만큼의 worker process가 생성이 됩니다 . 이 subprocess들이 data loading에 사용됩니다.


data를 loading할 때 에는 , enumerate(dataloader)를 call 하여 , 매번 DataLoader의 iterator를 생성합니다. 여기에서 , `num_workers' argument에 지정한 개수 만큼의 worker_process가 생성이 됩니다. 그리고 , 'dataset' , 'collate_fn', 'worker_init_fn'이 각  worker에 전달이 됩니다. worker가  initialize 된 후 ,   data가 fetch 되어집니다.   

즉 , Internal I/O , transformation('collate_fn' 포함)이  dataset access와 함께 , worker_process에서 실행되어짐을 의미합니다.


## Iterating DataLoader

실제로 , Data를 여러개의 worker에서 fetching 할 때에는 , torch.utils.data.get_worekr_info()라는 method를 사용합니다.   
이 function은 아래와 같은 항목을 return합니다.
+ worker_id
+ dataset replica
+ initial seed
+ .etc

main_process에서는 None을 return 하게 됩니다. Pytorch 개발자들은 이 function을 dataset code나 worker_init_fn에서 사용하여 code가 worker_process에서 실행중인지 아닌지를 판별하여 개별적인 dataset_replica를 configure합니다.   

특히, data sharding에 도움이 된다고 합니다.

### Map-style

map-style dataset에서 여러 subprocess들을 만들게 되면 , sampler를 사용해서 indicies를 만들게 되고 이를 각 worker에 전달하게 됩니다 . sampler에서의 shuffling 은 main process에서 수행이 되어집니다.   
즉, main process는 data loading에서 shuffle된 indicies를 worker에 할당하여 data를 loading하도록 합니다.   
아래의 코드 예시를 보도록 하겠습니다.
```python 
import torch

class MyMapDataset(torch.utils.data.Dataset) :
    def __init__(self , start , end) :
        super(MyMapDataset).__init__()
        assert end&gt;start , &quot;this example code only works with end&gt; = start&quot;

        self.start = start
        self.end = end 
        self.data = list(range(self.start,self.end))
    def __getitem__(self,idx) :
        
        worker_info  =torch.utils.data.get_worker_info()
        worker_id = worker_info.id
        print(f&quot;worekr_id : {worker_id} data : {self.data[idx]}\n&quot;)

        return self.data[idx]
    def __len__(self) :
        return len(self.data)


map_ds = MyMapDataset(3,100)


print(list(torch.utils.data.DataLoader(map_ds,num_workers=2)))

# worekr_id : 0 data : 3

# worekr_id : 1 data : 4
# worekr_id : 0 data : 5


# worekr_id : 1 data : 6
# worekr_id : 0 data : 7


# worekr_id : 1 data : 8
# worekr_id : 0 data : 9


# worekr_id : 1 data : 10
# worekr_id : 0 data : 11


# worekr_id : 1 data : 12
# worekr_id : 0 data : 13


# worekr_id : 1 data : 14
# worekr_id : 0 data : 15

# worekr_id : 1 data : 16


# worekr_id : 1 data : 18


#  ... 
# worekr_id : 0 data : 93
# worekr_id : 1 data : 96


# worekr_id : 0 data : 95
# worekr_id : 1 data : 98

# worekr_id : 0 data : 97
# worekr_id : 0 data : 99

# [tensor([3]), tensor([4]), tensor([5]), tensor([6]), tensor([7]), tensor([8]), tensor([9]), tensor([10]), tensor([11]), tensor([12]), tensor([13]), tensor([14]), tensor([15]), tensor([16]), tensor([17]), tensor([18]), tensor([19]), tensor([20]), tensor([21]), tensor([22]), tensor([23]), tensor([24]), tensor([25]), tensor([26]), tensor([27]), tensor([28]), tensor([29]), tensor([30]), tensor([31]), tensor([32]), tensor([33]), tensor([34]), tensor([35]), tensor([36]), tensor([37]), tensor([38]), tensor([39]), tensor([40]), tensor([41]), tensor([42]), tensor([43]), tensor([44]), tensor([45]), tensor([46]), tensor([47]), tensor([48]), tensor([49]), tensor([50]), tensor([51]), tensor([52]), tensor([53]), tensor([54]), tensor([55]), tensor([56]), tensor([57]), tensor([58]), tensor([59]), tensor([60]), tensor([61]), tensor([62]), tensor([63]), tensor([64]), tensor([65]), tensor([66]), tensor([67]), tensor([68]), tensor([69]), tensor([70]), tensor([71]), tensor([72]), tensor([73]), tensor([74]), tensor([75]), tensor([76]), tensor([77]), tensor([78]), tensor([79]), tensor([80]), tensor([81]), tensor([82]), tensor([83]), tensor([84]), tensor([85]), tensor([86]), tensor([87]), tensor([88]), tensor([89]), tensor([90]), tensor([91]), tensor([92]), tensor([93]), tensor([94]), tensor([95]), tensor([96]), tensor([97]), tensor([98]), tensor([99])]

```

보시는 바와 같이 각 indicies들이 worker에 전달되어 data를 loading함을 알 수 있습니다.

### Iterative-style
Iterable sytle의 dataset을 worker를 이용해서 loading할 때에는 data 중복을 주의해야 합니다.   
Iterable style의 dataset을 loading할 때 subprocess들을 만드는 경우 , 각 worker들이 dataset object의 replica를 얻게 됩니다. 그 다음에, 각 worker들이 dataset object를 iterating 함으로 써 , data의 중복이 발생하게 됩니다. 아래의 예시코드에서 확인해보도록 하겠습니다. 
```python

import torch

class MyIterableDataset(torch.utils.data.IterableDataset) :
    def __init__(self,start, end) :
        super(MyIterableDataset).__init__()
        assert end&gt;start , &quot;this example code only works with end &gt;=start&quot;

        self.start = start
        self.end = end
    def __iter__(self) :
        worker_info = torch.utils.data.get_worker_info()
        worker_id = worker_info.id
        print(range(self.start,self.end))
        print(worker_info)
        return iter(range(self.start,self.end))

ds = MyIterableDataset(start=3 ,end =100)

print(list(torch.utils.data.DataLoader(ds,num_workers=2)))

# range(3, 100)
# WorkerInfo(id=0, num_workers=2, seed=4911920692807402111, dataset=&lt;__main__.MyIterableDataset object at 0x7f5d2ef69910&gt;)range(3, 100)

# WorkerInfo(id=1, num_workers=2, seed=4911920692807402112, dataset=&lt;__main__.MyIterableDataset object at 0x7f5d2ef69910&gt;)
# [tensor([3]), tensor([3]), tensor([4]), tensor([4]), tensor([5]), tensor([5]), tensor([6]), tensor([6]), tensor([7]), tensor([7]), tensor([8]), tensor([8]), tensor([9]), tensor([9]), tensor([10]), tensor([10]), tensor([11]), tensor([11]), tensor([12]), tensor([12]), tensor([13]), tensor([13]), tensor([14]), tensor([14]), tensor([15]), tensor([15]), tensor([16]), tensor([16]), tensor([17]), tensor([17]), tensor([18]), tensor([18]), tensor([19]), tensor([19]), tensor([20]), tensor([20]), tensor([21]), tensor([21]), tensor([22]), tensor([22]), tensor([23]), tensor([23]), tensor([24]), tensor([24]), tensor([25]), tensor([25]), tensor([26]), tensor([26]), tensor([27]), tensor([27]), tensor([28]), tensor([28]), tensor([29]), tensor([29]), tensor([30]), tensor([30]), tensor([31]), tensor([31]), tensor([32]), tensor([32]), tensor([33]), tensor([33]), tensor([34]), tensor([34]), tensor([35]), tensor([35]), tensor([36]), tensor([36]), tensor([37]), tensor([37]), tensor([38]), tensor([38]), tensor([39]), tensor([39]), tensor([40]), tensor([40]), tensor([41]), tensor([41]), tensor([42]), tensor([42]), tensor([43]), tensor([43]), tensor([44]), tensor([44]), tensor([45]), tensor([45]), tensor([46]), tensor([46]), tensor([47]), tensor([47]), tensor([48]), tensor([48]), tensor([49]), tensor([49]), tensor([50]), tensor([50]), tensor([51]), tensor([51]), tensor([52]), tensor([52]), tensor([53]), tensor([53]), tensor([54]), tensor([54]), tensor([55]), tensor([55]), tensor([56]), tensor([56]), tensor([57]), tensor([57]), tensor([58]), tensor([58]), tensor([59]), tensor([59]), tensor([60]), tensor([60]), tensor([61]), tensor([61]), tensor([62]), tensor([62]), tensor([63]), tensor([63]), tensor([64]), tensor([64]), tensor([65]), tensor([65]), tensor([66]), tensor([66]), tensor([67]), tensor([67]), tensor([68]), tensor([68]), tensor([69]), tensor([69]), tensor([70]), tensor([70]), tensor([71]), tensor([71]), tensor([72]), tensor([72]), tensor([73]), tensor([73]), tensor([74]), tensor([74]), tensor([75]), tensor([75]), tensor([76]), tensor([76]), tensor([77]), tensor([77]), tensor([78]), tensor([78]), tensor([79]), tensor([79]), tensor([80]), tensor([80]), tensor([81]), tensor([81]), tensor([82]), tensor([82]), tensor([83]), tensor([83]), tensor([84]), tensor([84]), tensor([85]), tensor([85]), tensor([86]), tensor([86]), tensor([87]), tensor([87]), tensor([88]), tensor([88]), tensor([89]), tensor([89]), tensor([90]), tensor([90]), tensor([91]), tensor([91]), tensor([92]), tensor([92]), tensor([93]), tensor([93]), tensor([94]), tensor([94]), tensor([95]), tensor([95]), tensor([96]), tensor([96]), tensor([97]), tensor([97]), tensor([98]), tensor([98]), tensor([99]), tensor([99])]

```

dataset의 replica가 각 worker에 전달되어 중복되게 fetching함을 알 수 있습니다.   
이를 해결하기 위해서는 여러가지 방법이 있습니다. 

#### Using get_worker_info()

위에서 언급했듯이 , get_worker_info() 는 main_process의 경우 None을 return하고 , subprocess의 경우에는 id,replica ,seed 등등을 return합니다. worker_id를 이용해서 각 worker마다 fetching을 configuration을 할 수 있습니다.
```python
class MyIterableDataset(torch.utils.data.IterableDataset) :
    def __init__(self, start, end) :
        super(MyIterableDataset).__init__()
        assert end &gt; start , &quot;this example code only works with end &gt;= start&quot;

        self.start = start
        self.end = end
    
    def __iter__(self) :
        worker_info= torch.utils.data.get_worker_info()
        if worker_info is None :
            iter_start = self.start
            iter_end = self.end
        else :
            per_worker = int(math.ceil((self.end-self.start) ) /
                             float(worker_info.num_workers))
            worker_id = worker_info.id
            iter_start = self.start + worker_id * per_worker
            iter_end =  min(iter_start + per_worker , self.end)
            print(f'worker_id : {worker_id} \n iter_start : {iter_start}  iter_end : {iter_end}\n')
        return iter(range(iter_start, iter_end))


ds = MyIterableDataset(start = 3 ,end = 100) 


print(list(torch.utils.data.DataLoader(ds,num_workers=3)))


# worker_id : 0 
#  iter_start : 3  iter_end : 35
# worker_id : 1 
#  iter_start : 35  iter_end : 67


# worker_id : 2 
#  iter_start : 67  iter_end : 99

# [tensor([3]), tensor([35]), tensor([67]), tensor([4]), tensor([36]), tensor([68]), tensor([5]), tensor([37]), tensor([69]), tensor([6]), tensor([38]), tensor([70]), tensor([7]), tensor([39]), tensor([71]), tensor([8]), tensor([40]), tensor([72]), tensor([9]), tensor([41]), tensor([73]), tensor([10]), tensor([42]), tensor([74]), tensor([11]), tensor([43]), tensor([75]), tensor([12]), tensor([44]), tensor([76]), tensor([13]), tensor([45]), tensor([77]), tensor([14]), tensor([46]), tensor([78]), tensor([15]), tensor([47]), tensor([79]), tensor([16]), tensor([48]), tensor([80]), tensor([17]), tensor([49]), tensor([81]), tensor([18]), tensor([50]), tensor([82]), tensor([19]), tensor([51]), tensor([83]), tensor([20]), tensor([52]), tensor([84]), tensor([21]), tensor([53]), tensor([85]), tensor([22]), tensor([54]), tensor([86]), tensor([23]), tensor([55]), tensor([87]), tensor([24]), tensor([56]), tensor([88]), tensor([25]), tensor([57]), tensor([89]), tensor([26]), tensor([58]), tensor([90]), tensor([27]), tensor([59]), tensor([91]), tensor([28]), tensor([60]), tensor([92]), tensor([29]), tensor([61]), tensor([93]), tensor([30]), tensor([62]), tensor([94]), tensor([31]), tensor([63]), tensor([95]), tensor([32]), tensor([64]), tensor([96]), tensor([33]), tensor([65]), tensor([97]), tensor([34]), tensor([66]), tensor([98])]


```

위의 code에서 iter method는 subprocess가 설정되면 , num_workers만큼 data를 나누어서 worker_id를 기준으로 fetching하도록 configuration 합니다.



#### Using worker_init_fn(worker_id)

pytorch dataloader의 argument에는 worker_init_fn을 설정할 수 있습니다. worker_init_fn은 worker_id를 argument로 받아서, 각 dataset의 replica를 개별적으로 설정합니다.
```python
class MyIterableDataset(torch.utils.data.IterableDataset) :
    def __init__(self,start, end) :
        super(MyIterableDataset).__init__()
        assert end&gt;start , &quot;this example code only works with end &gt;=start&quot;

        self.start = start
        self.end = end
    def __iter__(self) :
        worker_info = torch.utils.data.get_worker_info()
        worker_id = worker_info.id
        print(f'worker_id : {worker_id} \n iter_start : {self.start}  iter_end : {self.end}\n')
        return iter(range(self.start,self.end))


def worker_init_fn(worker_id) :
    worker_info = torch.utils.data.get_worker_info()
    dataset = worker_info.dataset
    overall_start = dataset.start
    overall_end = dataset.end

    per_worker = int(math.ceil((overall_end-overall_start) ) /
                     float(worker_info.num_workers))
    worker_id = worker_info.id
    dataset.start = overall_start + worker_id * per_worker
    dataset.end = min(dataset.start + per_worker , overall_end)
    # print(f'worker_id : {worker_id} , worker_start : {dataset.start}  ,  worekr_end : {dataset.end}')


ds = MyIterableDataset(start = 3 ,end = 100) 


print(list(torch.utils.data.DataLoader(ds,num_workers=10,worker_init_fn=worker_init_fn)))


# /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
#   cpuset_checked))
# worker_id : 0 
#  iter_start : 3  iter_end : 12

# worker_id : 1 
#  iter_start : 12  iter_end : 21
# worker_id : 2 
#  iter_start : 21  iter_end : 30

# worker_id : 3 
#  iter_start : 30  iter_end : 39


# worker_id : 4 
#  iter_start : 39  iter_end : 48

# worker_id : 5 
#  iter_start : 48  iter_end : 57

# worker_id : 6 
#  iter_start : 57  iter_end : 66

# worker_id : 7 
#  iter_start : 66  iter_end : 75

# worker_id : 8 
#  iter_start : 75  iter_end : 84

# worker_id : 9 
#  iter_start : 84  iter_end : 93

# [tensor([3]), tensor([12]), tensor([21]), tensor([30]), tensor([39]), tensor([48]), tensor([57]), tensor([66]), tensor([75]), tensor([84]), tensor([4]), tensor([13]), tensor([22]), tensor([31]), tensor([40]), tensor([49]), tensor([58]), tensor([67]), tensor([76]), tensor([85]), tensor([5]), tensor([14]), tensor([23]), tensor([32]), tensor([41]), tensor([50]), tensor([59]), tensor([68]), tensor([77]), tensor([86]), tensor([6]), tensor([15]), tensor([24]), tensor([33]), tensor([42]), tensor([51]), tensor([60]), tensor([69]), tensor([78]), tensor([87]), tensor([7]), tensor([16]), tensor([25]), tensor([34]), tensor([43]), tensor([52]), tensor([61]), tensor([70]), tensor([79]), tensor([88]), tensor([8]), tensor([17]), tensor([26]), tensor([35]), tensor([44]), tensor([53]), tensor([62]), tensor([71]), tensor([80]), tensor([89]), tensor([9]), tensor([18]), tensor([27]), tensor([36]), tensor([45]), tensor([54]), tensor([63]), tensor([72]), tensor([81]), tensor([90]), tensor([10]), tensor([19]), tensor([28]), tensor([37]), tensor([46]), tensor([55]), tensor([64]), tensor([73]), tensor([82]), tensor([91]), tensor([11]), tensor([20]), tensor([29]), tensor([38]), tensor([47]), tensor([56]), tensor([65]), tensor([74]), tensor([83]), tensor([92])]
```


### Warning

Pytorch Docs에서는 CUDA Tensor를 multi-processing loading 에서 return하는 것을 추천하지 않는다고 한다.  CUDA Tensor를 공유하거나 CUDA를 사용하는 대신에 , automatic memory pinning(pin_memory = True)을 이용해서  사용하는 것을 추천한다고 합니다. 이는 CUDA가 사용가능한 GPO로 빠른 data 전송을 하게 한다고 합니다. 


## Platform Specific

Python Multiprocessing을 사용하게 되면, OS에 따라서 , worker launch behavior가 달라집니다. 

1. UNIX
    + fork()가  multiprocessing을 시작하는 default method입니다. fork()를 사용하면 , child worker들은 복제된 address space를 통해 dataset과 Python functions에 직접 access 할 수 있습니다. 
  
2. Windows, MAC 
   + spawn()이 multiprocessing을 시작하는 default method입니다. spawn()을 사용해서 , 다른 interpereter들이 실행되면서 , main script를 실행합니다. 그 다음에 , pickle serialization을 통해 dataset, collate_fn , 그리고 다른 argument를 serialization 하고 , internal worker function을 실행합니다. serialization을 사용한다는건 multiprocess data load를 사용하는동안에 Windows와 호환이 되는지 확인하는 2단계를 실행해야 함을 의미합니다.
        1. main script code를 `if __name__  =='__main__'` block으로 둘러쌉니다. 
           + why? 각 worker process가 실행될 때 , 다시는 main script code가 실행되지 않도록 하기 위해서입니다. main script code에 Dataset,Datalodaer instance 생성 코드를 포함시켜 , worker에서 다시 실행되지 않도록 합니다.
        2. custom collate_fn ,worker_init_fn , 그리고 dataset code가 top level definitions에서 ,즉 `__main__` 을 check하는 code 바깥에서  define되도록 합니다.
            + why? fucntions들이 bytecode가 아닌 reference로써 pickled 되기 때문입니다.

## Randomness in multiprocessing data loading

각 worker는 seed를  (base_seed + worker_id)로 설정합니다. base_seed는 main_process에 의해서 생성이 되는데 , 이 때 RNG(Random Number Generator) 나 지정한 generator를 이용하게 됩니다. 하지만, 다른 라이브러리의 seed가 중복이 될 수 있습니다. 따라서 ,  worker 가 initialized 될 때 , 각 worker가 동일한 random number를 return할 수 있습니다.   
worker_init_fn에서 torch.utils.data.get_worker_info().seed 나 torch.initial.seed를 사용하면 각 worker에 대한 Pytorch seed set에 access하고 , 이를 사용하여  , data 를 loading하기 전에 다른 라이브러리로 seed를 전달할 수 있습니다. 

## Issues
+ Problem
  + iteration을 몇 번 반복하고 나면 , loader worker process가 parent process에 있는 모든 Python Objects(worker process에서 access가능)에 대해 같은 양의 CPU Memory를 점유하고 있습니다.만약에 , Dataset이 엄청나게 큰 data(ex.매우 큰 filename lsit)를 포함하거나 수많은 worker를 사용한다면 문제가 발생할 것입니다.
+ Why?
  + 임의의 Python Objects를  shared memmory에 저장하는 것은 copy-on-write problem을 발생시킵니다. 이 object들을 read할 때마다 , reference count를 증가시킵니다. reference count의 변화로 인해 fork된 python process의 copy-on-acess problem이 발생하게 되는것입니다. (Memory-leak 문제가 아닙니다.)
+ Sol 
  + 기본적인 Python Objects(list,dict) 대신에 pandas,numpy,pyarrow 같은 objects를 사용합니다. 이들은 reference count가 1입니다.  
  + String을 저장할 때에는 , ASCII code로 numpy array를 사용하여 저장할 수 있습니다. 아니면, ByteCode나 Custom Datatype을 사용할 수 있습니다.
# References

[Pytorch-data-docs][Pytorch-data-api]

[Pytorch-data-api]: &quot;https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading&quot;</content><author><name>Choi Woongjoon</name></author><category term="Pytorch" /><category term="Machine Learning" /><category term="Pytorch" /><category term="deep learning" /><summary type="html">Pytorch multiprocess</summary></entry><entry><title type="html">Numerics</title><link href="http://localhost:4000/python/Numeric/" rel="alternate" type="text/html" title="Numerics" /><published>2022-09-12T00:00:00+09:00</published><updated>2022-09-12T00:00:00+09:00</updated><id>http://localhost:4000/python/Numeric</id><content type="html" xml:base="http://localhost:4000/python/Numeric/">Numeric Types라는 Built-in Objects를 잘 이용하기 위해서는 이 Built-in Objects에 어떤 Literals들이 있고 , 어떤 operator들을 제공하는지 알아야합니다. 이것들에 대해서 알아보도록 하겠습니다 .

# Numeric Literals
## Integers
Integer 타입은 decimal digits으로 쓰여진 string 입니다. 
예시는 아래와 같습니다.

```python
#  24, 0 ,-123234556

```


### Python 3.x vs Python 2.x
Python의 Integer는 precision에 제한이 없습니다. 
하지만 , 
&gt; Python 3.x 버전과 2.X버전에서의 Integer는 큰 차이점이 있습니다. 

2.x 버전에서는 Integer는 normal type과 long type으로 나뉩니다. normal integer는 32bit로 표현할 수 있는 decimal digit을 표현합니다. 하지만, long type은 precision에 제한이 없고 , decimal digit 끝이 l 혹은 L로 끝나게 됩니다. 허용된 bit인 32를 넘게되면, 자동으로 long integer로 변환이 됩니다.Programmer가 'L'을 type할 필요가 없습니다.
```python
2147689795
&gt;&gt;&gt;2147689795L

```


하지만, 3.x버전에서는 Integer는 normal type과 long type이 병합되었습니다. 따라서, integer는 더이상 l 이나 L이 끝에 출력도지 않습니다.
```python
2147689795
&gt;&gt;&gt;2147689795

```

### Hex,Binary,Oct

여태까지, 위에서 본 Integer는 전부 decimal digits로 코딩된 Integer였습니다. Integer는 decimal 뿐만 아니라, hexadecimal, octal, binary로 코딩될 수 있습니다.   
HexaDecimal은 (0x or 0X)(A-F and 0-9) 의 format으로 coding이 되어집니다. 
```python
a= 0xAF
print(a)
# 175
b = 0XAF

print(b)
```
말 그대로 코딩이 될 뿐 Integer이므로 출력은 Integer로 됩니다.

Octal은  (0o or 0O)(0-7) 의 format으로 coding이 되어집니다.  
2.x 버전에서는 0(0-7)의 format이였지만, decimal representation과 햇갈려서 3.x버전에서는 변경되었습니다.
```python
a = 0o10

print(a)
# 8
b= 0O10

print(b)

# 8
```

Binary는 (0b or 0B)(0-1) 의 format으로 coding이 되어집니다.

```python

a = 0b11

print(a)

# 3
b = 0B11

print(b)

# 3
```
#### Create Integers Using Built-in Calls

위에서 사용되었던 Integer의 format은 Built-in method로 생성할 수 있습니다.

```python

c = hex(16)

print(c)

print(type(c))

# 0x10
# &lt;class 'str'&gt;

c = oct(8)

print(c)

print(type(c))

# 0o10
# &lt;class 'str'&gt;


c = bin(2)

print(c)

print(type(c))

# 0b10
# &lt;class 'str'&gt;

```

hex,oct,bin 은 Integer를 argument로 받아 해당되는 representation을 string으로 return함을 알 수 있습니다.   

literal expression으로 Integer object를 생성할 수 있지만 , built-in method로도 Integer Objects를 생성할 수 있습니다. 

```python 

a = int(&quot;10&quot;,10)


print(f&quot;a : {a}&quot;)

print(f&quot; type of a : {type(a)}&quot;)
b = int(&quot;10&quot;,2)

print(f&quot;b : {b}&quot;)
print(f&quot; type of a : {type(b)}&quot;)

c = int(&quot;10&quot;,8)

print(f&quot;c : {c}&quot;)
print(f&quot; type of a : {type(c)}&quot;)
d = int(&quot;10&quot; , 16)

print(f&quot;d : {d}&quot;)
print(f&quot; type of a : {type(d)}&quot;)
e = int(&quot;10&quot;,3)

print(f&quot;e : {e}&quot;)
print(f&quot; type of a : {type(e)}&quot;)
k = int(6)
print(f&quot;k : {k}&quot;)
print(f&quot; type of a : {type(k)}&quot;)


# a : 10
#  type of a : &lt;class 'int'&gt;
# b : 2
#  type of a : &lt;class 'int'&gt;
# c : 8
#  type of a : &lt;class 'int'&gt;
# d : 16
#  type of a : &lt;class 'int'&gt;
# e : 3
#  type of a : &lt;class 'int'&gt;
# k : 6
#  type of a : &lt;class 'int'&gt;

```
int method는 int(str,base)  or int(digit) 로 정의되어 있습니다.
1. int(str,base)
   + base를 통해서 representation을 확인후 , 그 에 해당하는 integer objects를  return합니다
2. int(digit)
   + digit에 해당하는 intger object를 return합니다.

## Floating Numbers


```
floatnumber   ::=  pointfloat | exponentfloat
pointfloat    ::=  [digitpart] fraction | digitpart &quot;.&quot;
exponentfloat ::=  (digitpart | pointfloat) exponent
digitpart     ::=  digit ([&quot;_&quot;] digit)*
fraction      ::=  &quot;.&quot; digitpart
exponent      ::=  (&quot;e&quot; | &quot;E&quot;) [&quot;+&quot; | &quot;-&quot;] digitpart

```

floating literal의 lexical definition은 위와 같습니다.floatnumber는 pointfloat , exponentfloat 2가지의 literal로 구성되어집니다.  pointfloat , 즉 decimal 인 부분과 '.'으로만 이루어진 floatnumber입니다. exponentfloat은 추가적으로 exponent인 부분도 포함한다는 뜻입니다.   

Python에서 float literal를 사용하게 되면 , 이를 float object로 만들고  , floating object가 expression에서 사용되어 질 때 , floating-point math를 사용합니다.  floating object의 예시는 아래와 같습니다 .

```python 
print(3.14)

print(10.)

print(.0001)

print(1e100)

print(3.15e-10)

print(0e0)

# 3.14
# 10.0
# 0.0001
# 1e+100
# 3.15e-10
# 0.0

```

Floating-point number는 standard C python에서는 C의 &quot;doubles&quot;로 구현이 되어있습니다. 따라서, C compiler가 double에 제공하는 만큼의 precision을 얻게 됩니다. 

## Complex Numbers

복소수는 실수와 허수를 갖는 숫자입니다.

허수의 lexical definition은 아래와 같습니다.   
```
imagnumber ::=  (floatnumber | digitpart) (&quot;j&quot; | &quot;J&quot;)
```

복소수에서 실수부는 optional이므로 생략하여도 괜찮습니다.   
복소수의 예시는 아래와 같습니다.

```python 
print(3+5j)

print(type(3+5j))

b= 3.15j
print(b)
print(type(b))

b = 10.j

print(b)
print(type(b))

b = 10j

print(b)
print(type(b))

b=.001j
print(b)
print(type(b))


b=1e100j
print(b)
print(type(b))


b=3.14e-10j
print(b)
print(type(b))

b=3.14_15_93j

print(b)
print(type(b))

# (3+5j)
# &lt;class 'complex'&gt;
# 3.15j
# &lt;class 'complex'&gt;
# 10j
# &lt;class 'complex'&gt;
# 10j
# &lt;class 'complex'&gt;
# 0.001j
# &lt;class 'complex'&gt;
# 1e+100j
# &lt;class 'complex'&gt;
# 3.14e-10j
# &lt;class 'complex'&gt;
# 3.141593j
# &lt;class 'complex'&gt;


```
예를들어 ,3 + 5j 는 실수부 3, 허수부 5j를 가진 complex number입니다. 나머지는 , 허수만을 가진 complex number입니다.


# Handling Numeric Types Using Built-in tools

Numeric Types object를 정의를 했다면,이 objects에 대한 method 나 operator를 정의하여 Numeric type objects를 다룰 수 있습니다.   

## Expression Operator

[python-operator-list-and-precedence][python-operator-list-and-precedence]  

[python-operator-list-and-precedence]: &quot;https://docs.python.org/ko/3/reference/expressions.html#operator-precedence&quot;  

Python Operator의 목록과 우선순위는 documents site의 link를 첨부하도록 하겠습니다.  
 Documents에서의 table에서 위에 있을수록 precedence가 높고 , 같은 precedence라면 왼쪽에서 오른쪽으로 expression이 진행이 됩니다.     

Python Expression Operator에서는 알아야 할 몇가지 특징이 있습니다. 

1. 괄호에 둘러쌓인 expression을 먼저 수행합니다.
2. 서로 다른 type의 operands에 대해 expression을 수행할 때 , 더 복잡한 type의 operands로 type을 변환시킵니다. 그 다음에 , math operation을 수행합니다. 

```python
b = 40 + 3.14

print(type(b))

# &lt;class 'float'&gt;

```
물론 , 명시적으로 type을 변환할 수 있습니다.
```python

a = int(3.1425)
print(type(a))
print(a)
b= float(3)
print(b)
print(type(b))
# &lt;class 'int'&gt;
# 3
# &lt;class 'float'&gt;
#3.0 

```

즉, 자동적으로 type을 conversion 하기 때문에 , 명시적으로 type을 변환할 필요가 없습니다 .

## Built-in math functions and utitlity modules

Built-in math functions에는 pow , trunc,round , int 등등이 있고 , utility modules에는 random, math 등등이 있습니다. 

[Python-math-moduels][Python-math-modules]

[Python-math-modules]: &quot;https://docs.python.org/ko/3/library/numeric.html&quot;

math-modules에 대한 document link를 첨부하도록 하겠습니다.

# References


[Python-Types-docs][Python-Type-docs]

[Python-Type-docs]: &quot;https://docs.python.org/ko/3/library/stdtypes.html#numeric-types-int-float-complex&quot;

[Python-Lexical-analysis][Python-Lexical-analysis]  

[Python-Lexical-analysis]: &quot;https://docs.python.org/ko/3/reference/lexical_analysis.html#floating&quot;

Learning-Python</content><author><name>Choi Woongjoon</name></author><category term="Python" /><category term="Python" /><category term="Object" /><category term="Builtin" /><summary type="html">Python Numerics</summary></entry><entry><title type="html">Polynomial Regression</title><link href="http://localhost:4000/standfordml/polynominal-regerssion/" rel="alternate" type="text/html" title="Polynomial Regression" /><published>2022-06-02T00:00:00+09:00</published><updated>2022-06-02T00:00:00+09:00</updated><id>http://localhost:4000/standfordml/polynominal-regerssion</id><content type="html" xml:base="http://localhost:4000/standfordml/polynominal-regerssion/"># Polynomial Regression in Multiple Features

Linear Regression 모델을 1개의 독립변수 x와 1개의 의존변수 y로 나타내는 것을 Simple Linear Regression이라 한다. 이를 , 수식으로 표현하면  
$$
y = \theta_{1} x + \theta_{0}
$$
로 표현할 수 있다. 이는 단순하게 x,y 축을 가진 그래프로 표현할 수 있기에 쉽게 이해할 수 있습니다. 하지만, 의존변수 y를 예측해야하는 Linear Regression 모델을 만들때 , 독립변수는 1개가 아닐 수 있습니다. 이때 , 사용하는 LInear Regerssion 모델은 다른 equation입니다. 

## What is Polynomial Regression

Polynomial Regression이란 독립변수가 1개가 아닌 여러개인 경우의 Linear Regression 모델입니다.  

이를 식으로 표현하면  아래와 같습니다.


$$
\begin{align}
y &amp;= \theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{2} + ... + \theta_{n}x_{n} \\
y &amp;= \sum_{i=1}^{n} \theta_{i}x_{i} + \theta_{0} \\
\end{align}
$$

여기서 주의할 점은 모든 feature를사용하는 것이 아니라 , 필요한 만큼의 feature를 사용한다는 것입니다.

![image](https://user-images.githubusercontent.com/50165842/170036215-31ef848c-168f-4f1d-9f17-e7c39509d458.png)

예를 들어, 위와 같이 데이터가 주어진 경우에는 feature를 1개만 사용하면 충분합니다.

![image](https://user-images.githubusercontent.com/50165842/170036527-36e28dc6-2dea-4dab-8e9e-affe47055672.png)

이렇게 데이터가 주어진 경우 , feature를 2개 (x, x*x) 를 사용하게 된다면 , 빨간색과 같은  model을 얻게 될 것입니다. 이는 데이터를 잘 표현하지 못하는 model입니다. 

![image](https://user-images.githubusercontent.com/50165842/170037696-19d8cc0f-6b60-406e-b677-682a83f1e860.png)



만약에 , feature를 3개(x,x*x,x*x*x) 사용하게 된다면, 3차 함수가 되어서 , 위와 같은  model을 만들게 될 것입니다.



![image](https://user-images.githubusercontent.com/50165842/170037425-e9b1f125-6509-4e66-ae16-905a7445b020.png)

하지만 , feature를 다르게 사용한다면(x,x*x x*(1/2) (root x) ) 위와같이 점진적으로 증가하는 model이 되어서 데이터를 잘 표현하는 model이 될 것입니다. 



위의 데이터의 경우 , feature가 x1 ,x2... xn 만큼 주어졋다하더라도, 임의의 feature xk만을 사용하여 표현할 수 있고 , 이 feature의 지수를 어떻게 설정하느냐에 따라 data를 저 잘 표현할 수 있습니다.



## Learning Polynomial Regression 

model을 설정하였으면 ,  model을 학습해야 합니다. Polynomial Regression model 역시 Gradient Descent를 이용하여 학습을 진행합니다.

### Gradient Descent in Multiple Variables

우선 기존의 linear regression에서의 Gradient Descent를 equation으로 적으면 아래와 같습니다.
$$
\begin{align}
\theta_{0} := \theta_{1} - \alpha * {\partial J(\theta) \over \partial\theta_{0}} \\
\theta_{1} :=  \theta_{1} - \alpha * {\partial J(\theta) \over \partial\theta_{1}}

\end{align}
$$
Polynomial Regression의 경우에는 variable의 개수가 늘어나므로 여러번 update를 해주면 됩니다.
$$
\begin{align}
\theta_{0} &amp;:= \theta_{1} - \alpha * {\partial J(\theta) \over \partial\theta_{0}} \\
\theta_{1} &amp;:=  \theta_{1} - \alpha * {\partial J(\theta) \over \partial\theta_{1}} \\
\theta_{2} &amp;:=  \theta_{2} - \alpha * {\partial J(\theta) \over \partial\theta_{2}} \\
\theta_{3} &amp;:=  \theta_{3} - \alpha * {\partial J(\theta) \over \partial\theta_{3}} \\
&amp;...


\end{align}
$$
이를 일반화시키면 아래와 같은 eqation을 얻을 수 있습니다.
$$
\begin{align}

\theta_{k} &amp;:=  \theta_{k} - \alpha * {\partial J(\theta) \over \partial\theta_{k}} \\

(k &amp;= 1 ... n)

\end{align}
$$


### Convergence Speed

Polynomial Regression model을 학습할 방법을 알아봤습니다. 바로 학습에 들어가도 되지만, model 빠르게 convergence할수록 model을 학습하는 시간을 줄일 수 있습니다. 여러 hyperparameter들에 의해서 이 model이 convergence하는 시점이 빨라질 수 있습니다. 

#### Scaling Variables

![image](https://user-images.githubusercontent.com/50165842/170268003-1fd87952-68ed-492f-9ba4-e0169e7117ae.png)

Variable간의 scale 차이가 크다면 Loss Function이  위와 같은 형태를 보일 것입니다.  scale이 큰 variable의  parameter를 update하면 loss function의 값이 상대적으로 크게 변하고 , scale이 작은 variable의 parameter를 update하면 loss function의 값이 상대적으로 작게  변하기 때문에 위와같이 찌그러진 모양이 나오게 됩니다. 

#### Learning Rate

$$
\begin{align}

\theta_{k} &amp;:=  \theta_{k} - \alpha * {\partial J(\theta) \over \partial\theta_{k}} \\

(k &amp;= 1 ... n)

\end{align}
$$

Model의 weight를 update할 때  , $$\alpha$$ 라는 term을 곱하게 됩니다. 이 값을 learning rate라고 합니다. 만약에  , 이 learning rate값이 크다면,  loss function의 값이 아래와 같이 convergence 할 것입니다. convergence 값이 일정하게 감소하지 않을 것입니다.



![image](https://user-images.githubusercontent.com/50165842/171631540-d4abe530-7f8d-4327-bc79-462b28a0f437.png)

만약에 , learning rate 값이 작다면 , loss function의 값이 convergence하는데 시간이 오래 걸릴 것입니다.

![image](https://user-images.githubusercontent.com/50165842/171632233-0ca16407-0ddd-4db1-903e-ea386539c8d6.png)

learning rate값이 적절한 값을 가진다면, loss function의 값은 상대적으로 잘 convergence할 것입니다.



![image](https://user-images.githubusercontent.com/50165842/171632544-af33dc99-875b-4b16-899f-62bbd3e2da6f.png)

즉, 적절한 learning rate 값이란, 매 update마다 loss function의 값이 감소하면서 , 너무 적지 않게 감소하게 하는 값이라 할 수 있습니다. 



# References

Standford-ml [기계 학습  Coursera](https://www.coursera.org/learn/machine-learning)</content><author><name>Choi Woongjoon</name></author><category term="StandfordML" /><category term="Machine Learning" /><category term="LinearRegression" /><category term="StandfordML" /><summary type="html">Standford ML</summary></entry><entry><title type="html">What is Objects and Why use Built-in objects</title><link href="http://localhost:4000/python/Built-in-Objects/" rel="alternate" type="text/html" title="What is Objects and Why use Built-in objects" /><published>2022-05-26T00:00:00+09:00</published><updated>2022-05-26T00:00:00+09:00</updated><id>http://localhost:4000/python/Built-in-Objects</id><content type="html" xml:base="http://localhost:4000/python/Built-in-Objects/"># What is Objects?

Python을 이용하여 Program을 만들려면 Object를 이용하여 Program을 만들게 됩니다. Object를 이용해서 Program을 만드는 것은 당연하다고 볼 수 있지만, 왜 굳이 Built-in Type을 사용해야 될까요? 

## Python's Conceptual Hierachy

Python의 Object-Type을 이해할려면 Python Syntax가 어떤 계층으로 이루어져 있는지를 알아야 합니다. 

1. Program은 여러개의 Modules로 이루어져 있습니다.
2. Modules는 여러개의 Statements로 이루어져 있습니다.
3. Statement는 여러개의 Expression으로 이루어져 있습니다.
4. Expression은 Object-type을 process하거나 create 합니다.

즉, 연역법에 의해서 , Python의 Program은 Object-type을 통해서만 작동됨을 알 수 있습니다. 

다시 말하면 , Python의 Program은 Object가 어떻게 작동하는지 알아야 , Python Program을 의도하는대로 작동시킬 수 있습니다. 



## Why Use Built-in types?

Object를 잘 알아야하는 이유는 알겠는데 , 왜 굳이 Built-in Object Type을 사용할까요?  내가 필요한 Operation을 지원해주는 Object-Type을 사용하면 안될까요?

### C++,C  vs Python

 C++,C 에서하는 일을 생각해보면 Built-in type을 사용하는 이유를 알 수 있습니다. C,C++ 에서 주로 Object를 Implementation 하는데 초점이 맞추어져 있습니다. 이 object를 위해서 memory structure를 배치하고 ,  memory allocation을 관리하고  , 또한 search 와 access 루틴을 구현해야 합니다. 

하지만, Python에서는 Built-in Object를 사용한다면, C++,C에서 해야만 하는 작업들을 할 필요가 없습니다.

### Other Reasons

위 이유 이외에도 다양한 여러가지 이유가 있습니다.

1. 간단한 task의 경우 Built-in Object type이 내가 지금 풀고있는 problem domain에 필요로하는 data structure를 제공해줄 수 있습니다. 
2. 복잡한 task의 경우 , custom object나 c언어 interface를 사용해야 할 수 있습니다 .Built-in type objects는 custom object을 구성하는 요소입니다.
3. Built-in object는 custom data structure보다 효율적입니다. Python의 Built-in Object는 speed를 최적화하기 위해 C로 구현된 data structure를 사용합니다.

## Python's Core Data Type

Python의 Core Data Type은 아래와 같습니다.

- Object
- Numbers
- Strings
- Lists
- Dictionaries
- Files
- Sets
- Other Core Types
- Program Unit Types
- Implementation-related data types

# References



Learning Python(by Mark Lutz)  - chp 4</content><author><name>Choi Woongjoon</name></author><category term="Python" /><category term="Python" /><category term="Object" /><category term="Builtin" /><summary type="html">Python Objects</summary></entry></feed>